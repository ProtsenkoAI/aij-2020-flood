{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import features\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../datasets/\"\n",
    "s2m_path = \"../../working_data/handmade_s2m.csv\"\n",
    "\n",
    "hydro_path = data_dir + \"hydro_2018-2020/new_data_all.csv\"\n",
    "meteo_path = data_dir + \"meteo_new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date_fmt = \"%Y-%m-%d\"\n",
    "test_start_date, test_end_date = datetime.strptime(\"2020-11-23\", test_date_fmt), datetime.strptime(\"2020-12-03\", test_date_fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hydro manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_from_previous(series, lag):\n",
    "    return series.values[-lag] # use .values if breaks\n",
    "\n",
    "\n",
    "def lag1(series):\n",
    "    return lag_from_previous(series, 1)\n",
    "\n",
    "\n",
    "def lag2(series):\n",
    "    return lag_from_previous(series, 2)\n",
    "\n",
    "\n",
    "def func_for_n_last(series, func, n_last):\n",
    "    n_last_series = series.iloc[-n_last:] # use .values if breaks\n",
    "    return func(n_last_series)\n",
    "\n",
    "\n",
    "def mean_last_5_years(series):\n",
    "    return func_for_n_last(series, np.nanmean, 5)\n",
    "\n",
    "\n",
    "def std_last_5_years(series):\n",
    "    return func_for_n_last(series, np.nanstd, 5)\n",
    "\n",
    "doy_funcs = [lag1, lag2, mean_last_5_years, std_last_5_years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_params = [\n",
    "    [np.nanmean, 1, 7],\n",
    "    [np.nanmean, 1, 30],\n",
    "    [np.nanstd, 1, 30],\n",
    "    \n",
    "    [np.nanmax, 1, 7],\n",
    "    [np.nanmin, 1, 7],\n",
    "    \n",
    "    [np.nanmax, 1, 30],\n",
    "    [np.nanmin, 1, 30]\n",
    "]\n",
    "\n",
    "hydro_extract_config = {\n",
    "    \"lags\": np.arange(1, 8),\n",
    "    \"diff_lags\": [7],\n",
    "    \"diff_funcs\": [np.nanmean, np.nanstd],\n",
    "    \"levels_stat_config\": stat_params,\n",
    "    \"past_years_funcs\": doy_funcs\n",
    "}\n",
    "\n",
    "hydro_extractor = features.hydro.Extractor(hydro_extract_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_usage_config = {\n",
    "    \"lags\": 9,\n",
    "    \"diff\": 9, \n",
    "    \"levels_stat\": 32,\n",
    "    \"doy\": 365 * 5 + 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_loader = features.hydro.FileHydroLoader(hydro_path)\n",
    "hydro_extract_manager = features.hydro.ExtractManager(hydro_extractor, days_usage_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_manager = features.hydro.HydroManager(hydro_loader, hydro_extract_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meteo manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_dir_loader = features.meteo.DirMeteoLoader(meteo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_forecast_src = np.array([(\"Total_cloud_cover_entire_atmosphere_Mixed_intervals_Average\", \"cloudCoverTotal\"),\n",
    "                        ('u-component_of_wind_height_above_ground', \"windAngleX\"), \n",
    "                        ('v-component_of_wind_height_above_ground', \"windAngleY\"),\n",
    "                        ('Wind_speed_gust_surface', \"windSpeed\"), \n",
    "                        ('Total_precipitation_surface_Mixed_intervals_Accumulation', \"totalAccumulatedPrecipitation\"), \n",
    "                        (\"Temperature_height_above_ground\", 'airTemperature'), \n",
    "                        ('Maximum_temperature_height_above_ground_Mixed_intervals_Maximum', 'maximumTemperatureOverPeriodSpecified'), \n",
    "                        ('Minimum_temperature_height_above_ground_Mixed_intervals_Minimum', 'minimumTemperatureAtHeightAndOverPeriodSpecified'),\n",
    "                        ('Temperature_surface', 'soilTemperature'), \n",
    "                        ('Relative_humidity_height_above_ground', 'relativeHumidity'), \n",
    "                        ('Pressure_height_above_ground', 'pressure'), \n",
    "                        ('Pressure_reduced_to_MSL_msl', 'pressureReducedToMeanSeaLevel'),\n",
    "                        (\"Dewpoint_temperature_height_above_ground\", \"dewpointTemperature\")\n",
    "                       ])\n",
    "\n",
    "retrieved_vars = list(name_forecast_src[:, 1])\n",
    "varnames_table = pd.DataFrame(name_forecast_src, columns=[\"forecast\", \"src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_parser = features.meteo.ForecastParser()\n",
    "forecast_preprocessor = features.meteo.ForecastMeteoPreprocessor()\n",
    "coords_builder = features.CoordsBuilder(data_dir + \"processed_data/asunp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_forecast_loader = features.meteo.ForecastMeteoLoader(test_start_date, test_end_date, coords_builder, \n",
    "                                                          retrieved_vars, varnames_table, forecast_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_extract_config_builder = features.meteo.ExtrConfigBuilder()\n",
    "\n",
    "ordinal_extr_stats = [{\"func\": np.nanmean, \"lag\": 1, \"winsize\": 7}, \n",
    "                      {\"func\": np.nanmean, \"lag\": 7, \"winsize\": 30}, \n",
    "                      {\"func\": np.nanstd, \"lag\": 7, \"winsize\": 30}]\n",
    "\n",
    "ordinal_cols = [\"cloudCoverTotal\", \"windSpeed\", \"totalAccumulatedPrecipitation\", \"soilTemperature\",\n",
    "                            \"airTemperature\", \"dewpointTemperature\", \"pressure\", \"pressureReducedToMeanSeaLevel\",\n",
    "                            \"windAngleX\", \"windAngleY\"]\n",
    "\n",
    "min_extr_stats = [{\"func\": np.nanmean, \"lag\": 1, \"winsize\": 7}]\n",
    "min_cols = [\"minimumTemperatureAtHeightAndOverPeriodSpecified\", \"maximumTemperatureOverPeriodSpecified\"]\n",
    "\n",
    "meteo_extract_config_builder.update_with_config_and_cols(ordinal_extr_stats, ordinal_cols)\n",
    "meteo_extract_config_builder.update_with_config_and_cols(min_extr_stats, min_cols)\n",
    "meteo_extract_config_builder.set_diff_params(min_extr_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_extract_manager = features.meteo.MeteoExtractManager(meteo_extract_config_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_dropper = features.meteo.DirMeteoDropper()\n",
    "dir_dt_builder = features.meteo.DtBuilder()\n",
    "\n",
    "diff_cols = [\"cloudCoverTotal\", \"windSpeed\", \"totalAccumulatedPrecipitation\", \"soilTemperature\", \"airTemperature\", \n",
    "                        \"relativeHumidity\", \"pressureReducedToMeanSeaLevel\", \"windAngleX\", \"windAngleY\"]\n",
    "\n",
    "dir_preprocessor = features.meteo.DirMeteoPreprocessor(dir_dropper, dir_dt_builder, diff_cols)\n",
    "forecast_preprocessor = features.meteo.ForecastMeteoPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_manager = features.meteo.MeteoManager(meteo_dir_loader, meteo_forecast_loader, dir_preprocessor,\n",
    "                                           forecast_preprocessor, meteo_extract_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBuilder:\n",
    "    # TODO: функции доступа к date и id, тк сейчас они то в колоноках,\n",
    "    # то в индексах, так что вылетают рандомные ошибки\n",
    "    def __init__(self, s2m_dict):\n",
    "        self.s2m_dict = s2m_dict\n",
    "    \n",
    "    def build(self, hydro, meteo):\n",
    "        hydro = self.prepare_df(hydro)\n",
    "        meteo = self.prepare_df(meteo)\n",
    "        \n",
    "        hydro, meteo = self.fill_missing_dates(hydro, meteo)\n",
    "        merged = self.merge_parts(hydro, meteo)\n",
    "        \n",
    "        return self.extract_merged_x_y(merged)\n",
    "        \n",
    "        #return self.features, self.target\n",
    "    \n",
    "    def prepare_df(self, df):\n",
    "        df = df.reset_index()\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        first2cols = list(df.columns[:2])\n",
    "        df.set_index(first2cols, inplace=True)\n",
    "        df = features.utils.reduce_memory_usage(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def fill_missing_dates(self, hydro, meteo):\n",
    "        min_date, max_date = self.min_max_data_date(hydro, meteo)\n",
    "        \n",
    "        new_hydro_idx = self.create_all_dates_index(hydro, min_date, max_date)\n",
    "        new_meteo_idx = self.create_all_dates_index(meteo, min_date, max_date)\n",
    "        \n",
    "        fill_val = np.nan\n",
    "        hydro = hydro.reindex(new_hydro_idx, fill_value=fill_val)\n",
    "        meteo = meteo.reindex(new_meteo_idx, fill_value=fill_val)\n",
    "        \n",
    "        return hydro, meteo\n",
    "    \n",
    "    def min_max_data_date(self, hydro, meteo):\n",
    "        dates_hydro = hydro.index.get_level_values(\"date\")\n",
    "        dates_meteo = meteo.index.get_level_values(\"date\")\n",
    "        \n",
    "        min_date = min(dates_hydro.min(), dates_meteo.min())\n",
    "        max_date = max(dates_hydro.max(), dates_meteo.max())\n",
    "        \n",
    "        return min_date, max_date\n",
    "    \n",
    "    def create_all_dates_index(self, df, min_date, max_date):\n",
    "        id_idxs = df.index.get_level_values(0).unique()\n",
    "        new_date_index = pd.date_range(min_date, max_date, name=\"date\")\n",
    "        \n",
    "        all_dates_index = pd.MultiIndex.from_product([id_idxs, new_date_index])\n",
    "        \n",
    "        return all_dates_index\n",
    "    \n",
    "    def merge_parts(self, hydro, meteo):\n",
    "        nearest_meteo_id = self.hydro_to_meteo_map_col(hydro)\n",
    "        \n",
    "        hydro = hydro.reset_index()\n",
    "\n",
    "        merged = hydro.merge(meteo, left_on=[nearest_meteo_id, \"date\"], right_on=[\"stationNumber\", \"date\"], how=\"left\")\n",
    "        merged.set_index([\"id\", \"date\"], inplace=True)\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def hydro_to_meteo_map_col(self, hydro):\n",
    "        hydro_id = hydro.index.get_level_values(\"id\")\n",
    "        print(hydro_id)\n",
    "        print(self.s2m_dict)\n",
    "        hydro_nearest_meteo = hydro_id.map(self.s2m_dict)\n",
    "        \n",
    "        return hydro_nearest_meteo\n",
    "    \n",
    "    def extract_merged_x_y(self, merged):\n",
    "        feature_cols = list(merged.columns)\n",
    "        feature_cols.remove(\"target\")\n",
    "\n",
    "        features = merged[feature_cols]\n",
    "        target = merged[\"target\"]\n",
    "        \n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2m_dict = pd.read_csv(s2m_path, index_col=0).to_dict()[\"meteo_id\"]\n",
    "data_builder = DataBuilder(s2m_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_features_manager = features.StationFeatureManager(hydro_manager, meteo_manager, data_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 target\n",
      "id   date              \n",
      "5001 1984-01-01   258.0\n",
      "     1984-01-02   255.0\n",
      "     1984-01-03   252.0\n",
      "     1984-01-04   248.0\n",
      "     1984-01-05   244.0\n",
      "...                 ...\n",
      "6574 2018-12-27    21.0\n",
      "     2018-12-28    21.0\n",
      "     2018-12-29    21.0\n",
      "     2018-12-30    21.0\n",
      "     2018-12-31    21.0\n",
      "\n",
      "[2231619 rows x 1 columns]\n",
      "start hydro extraction\n",
      "water_levels extract                  target\n",
      "id   date              \n",
      "5001 1984-01-01   258.0\n",
      "     1984-01-02   255.0\n",
      "     1984-01-03   252.0\n",
      "     1984-01-04   248.0\n",
      "     1984-01-05   244.0\n",
      "...                 ...\n",
      "6574 2020-09-27     NaN\n",
      "     2020-09-28     NaN\n",
      "     2020-09-29     NaN\n",
      "     2020-09-30     NaN\n",
      "     2020-10-01     NaN\n",
      "\n",
      "[2657952 rows x 1 columns]\n",
      "filled missing dates\n",
      "                 target\n",
      "id   date              \n",
      "5001 1984-01-01   258.0\n",
      "extracting levels stats\n",
      "[[<function nanmean at 0x7ff1980fa0d0>, 1, 7], [<function nanmean at 0x7ff1980fa0d0>, 1, 30], [<function nanstd at 0x7ff1980faca0>, 1, 30], [<function nanmax at 0x7ff1980f44c0>, 1, 7], [<function nanmin at 0x7ff1980f4310>, 1, 7], [<function nanmax at 0x7ff1980f44c0>, 1, 30], [<function nanmin at 0x7ff1980f4310>, 1, 30]]\n",
      "colnames ['water_levels_nanmean_1_7', 'water_levels_nanmean_1_30', 'water_levels_nanstd_1_30', 'water_levels_nanmax_1_7', 'water_levels_nanmin_1_7', 'water_levels_nanmax_1_30', 'water_levels_nanmin_1_30']\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "levels stats                  water_levels_nanmean_1_7  water_levels_nanmean_1_30  \\\n",
      "id   date                                                              \n",
      "5001 1984-01-01                       NaN                        NaN   \n",
      "     1984-01-02                    258.00                     258.00   \n",
      "     1984-01-03                    256.50                     256.50   \n",
      "     1984-01-04                    255.00                     255.00   \n",
      "     1984-01-05                    253.25                     253.25   \n",
      "...                                   ...                        ...   \n",
      "6574 2020-09-27                       NaN                        NaN   \n",
      "     2020-09-28                       NaN                        NaN   \n",
      "     2020-09-29                       NaN                        NaN   \n",
      "     2020-09-30                       NaN                        NaN   \n",
      "     2020-10-01                       NaN                        NaN   \n",
      "\n",
      "                 water_levels_nanstd_1_30  water_levels_nanmax_1_7  \\\n",
      "id   date                                                            \n",
      "5001 1984-01-01                       NaN                      NaN   \n",
      "     1984-01-02                       NaN                    258.0   \n",
      "     1984-01-03                  2.121320                    258.0   \n",
      "     1984-01-04                  3.000000                    258.0   \n",
      "     1984-01-05                  4.272002                    258.0   \n",
      "...                                   ...                      ...   \n",
      "6574 2020-09-27                       NaN                      NaN   \n",
      "     2020-09-28                       NaN                      NaN   \n",
      "     2020-09-29                       NaN                      NaN   \n",
      "     2020-09-30                       NaN                      NaN   \n",
      "     2020-10-01                       NaN                      NaN   \n",
      "\n",
      "                 water_levels_nanmin_1_7  water_levels_nanmax_1_30  \\\n",
      "id   date                                                            \n",
      "5001 1984-01-01                      NaN                       NaN   \n",
      "     1984-01-02                    258.0                     258.0   \n",
      "     1984-01-03                    255.0                     258.0   \n",
      "     1984-01-04                    252.0                     258.0   \n",
      "     1984-01-05                    248.0                     258.0   \n",
      "...                                  ...                       ...   \n",
      "6574 2020-09-27                      NaN                       NaN   \n",
      "     2020-09-28                      NaN                       NaN   \n",
      "     2020-09-29                      NaN                       NaN   \n",
      "     2020-09-30                      NaN                       NaN   \n",
      "     2020-10-01                      NaN                       NaN   \n",
      "\n",
      "                 water_levels_nanmin_1_30  \n",
      "id   date                                  \n",
      "5001 1984-01-01                       NaN  \n",
      "     1984-01-02                     258.0  \n",
      "     1984-01-03                     255.0  \n",
      "     1984-01-04                     252.0  \n",
      "     1984-01-05                     248.0  \n",
      "...                                   ...  \n",
      "6574 2020-09-27                       NaN  \n",
      "     2020-09-28                       NaN  \n",
      "     2020-09-29                       NaN  \n",
      "     2020-09-30                       NaN  \n",
      "     2020-10-01                       NaN  \n",
      "\n",
      "[2657952 rows x 7 columns]\n",
      "lags turn\n",
      "lags                  lag[<function nanmean at 0x7ff1980fa0d0>, 1, 7]  \\\n",
      "id   date                                                          \n",
      "5001 1984-01-01                                              NaN   \n",
      "     1984-01-02                                            258.0   \n",
      "     1984-01-03                                            255.0   \n",
      "     1984-01-04                                            252.0   \n",
      "     1984-01-05                                            248.0   \n",
      "...                                                          ...   \n",
      "6574 2020-09-27                                              NaN   \n",
      "     2020-09-28                                              NaN   \n",
      "     2020-09-29                                              NaN   \n",
      "     2020-09-30                                              NaN   \n",
      "     2020-10-01                                              NaN   \n",
      "\n",
      "                 lag[<function nanmean at 0x7ff1980fa0d0>, 1, 30]  \\\n",
      "id   date                                                           \n",
      "5001 1984-01-01                                               NaN   \n",
      "     1984-01-02                                               NaN   \n",
      "     1984-01-03                                             258.0   \n",
      "     1984-01-04                                             255.0   \n",
      "     1984-01-05                                             252.0   \n",
      "...                                                           ...   \n",
      "6574 2020-09-27                                               NaN   \n",
      "     2020-09-28                                               NaN   \n",
      "     2020-09-29                                               NaN   \n",
      "     2020-09-30                                               NaN   \n",
      "     2020-10-01                                               NaN   \n",
      "\n",
      "                 lag[<function nanstd at 0x7ff1980faca0>, 1, 30]  \\\n",
      "id   date                                                          \n",
      "5001 1984-01-01                                              NaN   \n",
      "     1984-01-02                                              NaN   \n",
      "     1984-01-03                                              NaN   \n",
      "     1984-01-04                                            258.0   \n",
      "     1984-01-05                                            255.0   \n",
      "...                                                          ...   \n",
      "6574 2020-09-27                                              NaN   \n",
      "     2020-09-28                                              NaN   \n",
      "     2020-09-29                                              NaN   \n",
      "     2020-09-30                                              NaN   \n",
      "     2020-10-01                                              NaN   \n",
      "\n",
      "                 lag[<function nanmax at 0x7ff1980f44c0>, 1, 7]  \\\n",
      "id   date                                                         \n",
      "5001 1984-01-01                                             NaN   \n",
      "     1984-01-02                                             NaN   \n",
      "     1984-01-03                                             NaN   \n",
      "     1984-01-04                                             NaN   \n",
      "     1984-01-05                                           258.0   \n",
      "...                                                         ...   \n",
      "6574 2020-09-27                                             NaN   \n",
      "     2020-09-28                                             NaN   \n",
      "     2020-09-29                                             NaN   \n",
      "     2020-09-30                                             NaN   \n",
      "     2020-10-01                                             NaN   \n",
      "\n",
      "                 lag[<function nanmin at 0x7ff1980f4310>, 1, 7]  \\\n",
      "id   date                                                         \n",
      "5001 1984-01-01                                             NaN   \n",
      "     1984-01-02                                             NaN   \n",
      "     1984-01-03                                             NaN   \n",
      "     1984-01-04                                             NaN   \n",
      "     1984-01-05                                             NaN   \n",
      "...                                                         ...   \n",
      "6574 2020-09-27                                             NaN   \n",
      "     2020-09-28                                             NaN   \n",
      "     2020-09-29                                             NaN   \n",
      "     2020-09-30                                             NaN   \n",
      "     2020-10-01                                             NaN   \n",
      "\n",
      "                 lag[<function nanmax at 0x7ff1980f44c0>, 1, 30]  \\\n",
      "id   date                                                          \n",
      "5001 1984-01-01                                              NaN   \n",
      "     1984-01-02                                              NaN   \n",
      "     1984-01-03                                              NaN   \n",
      "     1984-01-04                                              NaN   \n",
      "     1984-01-05                                              NaN   \n",
      "...                                                          ...   \n",
      "6574 2020-09-27                                              NaN   \n",
      "     2020-09-28                                              NaN   \n",
      "     2020-09-29                                              NaN   \n",
      "     2020-09-30                                              NaN   \n",
      "     2020-10-01                                              NaN   \n",
      "\n",
      "                 lag[<function nanmin at 0x7ff1980f4310>, 1, 30]  \n",
      "id   date                                                         \n",
      "5001 1984-01-01                                              NaN  \n",
      "     1984-01-02                                              NaN  \n",
      "     1984-01-03                                              NaN  \n",
      "     1984-01-04                                              NaN  \n",
      "     1984-01-05                                              NaN  \n",
      "...                                                          ...  \n",
      "6574 2020-09-27                                              NaN  \n",
      "     2020-09-28                                              NaN  \n",
      "     2020-09-29                                              NaN  \n",
      "     2020-09-30                                              NaN  \n",
      "     2020-10-01                                              NaN  \n",
      "\n",
      "[2657952 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gldsn/.local/share/virtualenvs/aij20-flood-lIcseS5N/lib/python3.8/site-packages/pandas/core/apply.py:300: RuntimeWarning: Mean of empty slice\n",
      "  results[i] = self.f(v)\n",
      "/home/gldsn/.local/share/virtualenvs/aij20-flood-lIcseS5N/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1664: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg func: lag1\n",
      "agg func: lag2\n",
      "agg func: mean_last_5_years\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-597b9c222e48>:15: RuntimeWarning: Mean of empty slice\n",
      "  return func(n_last_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg func: std_last_5_years\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gldsn/.local/share/virtualenvs/aij20-flood-lIcseS5N/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1664: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/gldsn/.local/share/virtualenvs/aij20-flood-lIcseS5N/lib/python3.8/site-packages/pandas/core/frame.py:4300: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "../features/meteo/preprocessors.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[col == 12] = 9.5  # согласно README, это \"10\" с просветами\n",
      "../features/meteo/preprocessors.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[col == 11] = 0.05  # следы облаков\n",
      "../features/meteo/preprocessors.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[col == 13] = np.nan  # облака невозможно определить\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n"
     ]
    }
   ],
   "source": [
    "train = station_features_manager.get_whole_past()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gldsn/.local/share/virtualenvs/aij20-flood-lIcseS5N/lib/python3.8/site-packages/pandas/core/frame.py:4300: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "../features/meteo/preprocessors.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[col == 12] = 9.5  # согласно README, это \"10\" с просветами\n",
      "../features/meteo/preprocessors.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[col == 11] = 0.05  # следы облаков\n",
      "../features/meteo/preprocessors.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[col == 13] = np.nan  # облака невозможно определить\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n"
     ]
    }
   ],
   "source": [
    "meteo = station_features_manager.meteo_manager.make_past_features()\n",
    "meteo.to_csv(\"meteo_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meteo = pd.read_csv(\"meteo_features.csv\")\n",
    "# hydro = pd.read_csv(\"hydro_features.csv\")\n",
    "# meteo.set_index([\"stationNumber\", \"date\"], inplace=True)\n",
    "# hydro.set_index([\"id\", \"date\"], inplace=True)\n",
    "\n",
    "# s2m_dict = pd.read_csv(s2m_path, index_col=0).to_dict()[\"meteo_id\"]\n",
    "# data_builder = DataBuilder(s2m_dict)\n",
    "\n",
    "# train = data_builder.build(hydro, meteo)\n",
    "# train\n",
    "\n",
    "# past_features, past_target = train\n",
    "# past_features.to_csv(\"past_features.csv\")\n",
    "# past_target.to_csv(\"past_target.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
