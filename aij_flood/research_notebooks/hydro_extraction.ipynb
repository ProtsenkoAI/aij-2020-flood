{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# возможные глоб. фичи:\n",
    "# groupby: year, month, id (в различных коминациях)\n",
    "# функции: mean, std, mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import utils\n",
    "import os\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../\"\n",
    "data_dir = os.path.join(root_dir, \"working_data/\")\n",
    "\n",
    "water_levels_path = os.path.join(data_dir, \"water_levels.csv\")\n",
    "# corrs_dists_path = os.path.join(data_dir, \"corrs_and_dists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_coords = pd.read_csv(data_dir + \"hydro_posts_coords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5001</th>\n",
       "      <th>1984-01-01</th>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-02</th>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-03</th>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-04</th>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-05</th>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 max_level\n",
       "id   date                 \n",
       "5001 1984-01-01      258.0\n",
       "     1984-01-02      255.0\n",
       "     1984-01-03      252.0\n",
       "     1984-01-04      248.0\n",
       "     1984-01-05      244.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_levels = pd.read_csv(water_levels_path)\n",
    "water_levels[\"date\"] = pd.to_datetime(water_levels[\"date\"], format=\"%Y-%m-%d\")\n",
    "water_levels.set_index([\"id\", \"date\"], inplace=True)\n",
    "water_levels = utils.reduce_memory_usage(water_levels)\n",
    "\n",
    "water_levels.head()\n",
    "\n",
    "# corr_and_nearest = pd.read_csv(corrs_dists_path)\n",
    "# corr_and_nearest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_dates(water_levels, fill_val=np.nan):\n",
    "    dates = water_levels.index.get_level_values(1)\n",
    "    min_date, max_date = dates.min(), dates.max()\n",
    "    \n",
    "    new_index = pd.MultiIndex.from_product([water_levels.index.get_level_values(0).unique(), \n",
    "                                            pd.date_range(min_date, max_date, name=\"date\")])\n",
    "    water_levels = water_levels.reindex(new_index, fill_value=fill_val)\n",
    "    return water_levels\n",
    "\n",
    "# water_levels = fill_missing_dates(water_levels)\n",
    "# water_levels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df, func, func_args_list):\n",
    "    id_groups = df.groupby(by=\"id\")\n",
    "    features = []\n",
    "    \n",
    "    for func_args in func_args_list:\n",
    "        if not isinstance(func_args, Iterable):\n",
    "            func_args = (func_args,)\n",
    "        func_out = func(id_groups, *func_args)\n",
    "            \n",
    "        features.append(func_out)\n",
    "        \n",
    "    features_df = pd.concat(features, axis=1)\n",
    "    return features_df\n",
    "\n",
    "\n",
    "def lag(grouped, lag):\n",
    "    feature = grouped.shift(lag)\n",
    "    \n",
    "    feature_name = f\"lag_{lag}\"\n",
    "    feature = rename_first_col(feature, feature_name)\n",
    "    \n",
    "    return feature\n",
    "\n",
    "\n",
    "def stat(grouped, func, lag, winsize):\n",
    "    shifted_grouped = grouped.shift(lag).groupby(\"id\")\n",
    "    \n",
    "    print(\"start extracting\")\n",
    "    feature = shifted_grouped.rolling(winsize, min_periods=1).agg(func)\n",
    "    print(\"end!\")\n",
    "    \n",
    "    feature = drop_redundant_agg_indexes(feature)\n",
    "    \n",
    "    feature_name = f\"{func.__name__}_{lag}_{winsize}\"\n",
    "    feature = rename_first_col(feature, feature_name)\n",
    "    \n",
    "    return feature\n",
    "\n",
    "\n",
    "def drop_redundant_agg_indexes(df):\n",
    "    df.index = df.index.droplevel(0) # agg creates second id col\n",
    "    return df\n",
    "\n",
    "\n",
    "def rename_first_col(df, new_name):\n",
    "    old_name = df.columns[0]\n",
    "    new_name = f\"{old_name}_\" + new_name\n",
    "    \n",
    "    return df.rename(columns={old_name: new_name})\n",
    "\n",
    "# def mean_previous_years(df):\n",
    "#     feature = \n",
    "\n",
    "    \n",
    "# def last_year_records(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_lag(grouped, ndays):\n",
    "    differences = grouped.diff(1).groupby(\"id\").shift(1).groupby(\"id\") #group again to roll by groups not whole df\n",
    "    \n",
    "    feature_names = [f\"diff_{i}\" for i in range(1, ndays+1)]\n",
    "    diff_lags = differences.rolling(ndays, min_periods=1) # need shift to get only previous values without current one\n",
    "    \n",
    "    diff_lags = all_rolling_lags(diff_lags, ndays)\n",
    "    \n",
    "    diff_lags_df = pd.DataFrame(diff_lags, columns=feature_names)\n",
    "    return diff_lags_df\n",
    "        \n",
    "    \n",
    "def all_rolling_lags(roll, ndays):\n",
    "    vals = []\n",
    "    for window in enumerate(roll):\n",
    "        window_vals_flipped = window[1].values[:, 0]\n",
    "        # window is took from earlier days to later, so we flip it to lag format (1 col is lag 1 day ago etc)\n",
    "        window_vals = np.flip(window_vals_flipped)\n",
    "        \n",
    "        win_len = window_vals.shape[0]\n",
    "        \n",
    "        if win_len < ndays:\n",
    "            padding_array = np.full(ndays - win_len, np.nan)\n",
    "            padded_window_values = np.concatenate((window_vals, padding_array))\n",
    "            \n",
    "        else:\n",
    "            padded_window_values = window_vals\n",
    "            \n",
    "        vals.append(padded_window_values)\n",
    "    return np.array(vals)\n",
    "\n",
    "# diff_lags = extract_features(water_levels, diff_lag, [7])\n",
    "# diff_lags.index = water_levels.index\n",
    "# diff_lags.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff_lags_stats(diff_lags, funcs):\n",
    "    \n",
    "    features = []\n",
    "    for func in funcs:\n",
    "        print(func.__name__)\n",
    "        f_name = f\"diff_{func.__name__}\"\n",
    "        feature = diff_lags.apply(func, axis=1)\n",
    "        feature.name = f_name\n",
    "        features.append(feature)\n",
    "    \n",
    "    features_df = pd.concat(features, axis=1)\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_lags_stats = calc_diff_lags_stats(diff_lags, [np.nanmean, np.nanstd])\n",
    "# diff_lags_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lags = extract_features(water_levels, lag, np.arange(1, 8))\n",
    "# lags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_config = [\n",
    "#     [np.nanmean, 1, 7],\n",
    "#     [np.nanmean, 1, 30],\n",
    "#     [np.nanstd, 1, 30],\n",
    "    \n",
    "#     [np.nanmax, 1, 7],\n",
    "#     [np.nanmin, 1, 7],\n",
    "    \n",
    "#     [np.nanmax, 1, 30],\n",
    "#     [np.nanmin, 1, 30]\n",
    "# ]\n",
    "\n",
    "# stats = extract_features(water_levels, stat, stat_config)\n",
    "# stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def past_years_stats(df, funcs):\n",
    "    months = df.index.get_level_values(\"date\").month\n",
    "    days = df.index.get_level_values(\"date\").day\n",
    "    station = df.index.get_level_values(\"id\")\n",
    "    \n",
    "    same_doy = df[\"max_level\"].groupby([months, days, station])\n",
    "    same_doy_previous = same_doy.shift(1).groupby([months, days, station])\n",
    "    \n",
    "    features = []\n",
    "    for func in funcs:\n",
    "        print(f\"agg func: {func.__name__}\")\n",
    "    #agg from previous because we have no water level of x year's doy when calc features for this year's doy\n",
    "        feature = same_doy_previous.expanding(min_periods=1).agg(func) \n",
    "        f_name = f\"doy_{func.__name__}\"\n",
    "#         feature = rename_first_col(feature, f_name)\n",
    "        feature.name = f_name\n",
    "        features.append(feature)\n",
    "        \n",
    "    features_df = pd.concat(features, axis=1)\n",
    "    features_df = features_df.droplevel([0, 1, 2]).sort_index(level=[\"id\", \"date\"])\n",
    "        \n",
    "    return features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_from_previous(series, lag):\n",
    "    return series.iloc[-lag] # use .values if breaks\n",
    "\n",
    "def lag1(series):\n",
    "    return lag_from_previous(series, 1)\n",
    "\n",
    "def lag2(series):\n",
    "    return lag_from_previous(series, 2)\n",
    "\n",
    "def func_for_n_last(series, func, n_last):\n",
    "#     start_idx = max(len(series) - n_last, 0)\n",
    "    n_last_series = series.iloc[-n_last:] # use .values if breaks\n",
    "    return func(n_last_series)\n",
    "\n",
    "def mean_last_5_years(series):\n",
    "    return func_for_n_last(series, np.nanmean, 5)\n",
    "\n",
    "def std_last_5_years(series):\n",
    "    return func_for_n_last(series, np.nanstd, 5)\n",
    "\n",
    "# doy_stats = past_years_stats(water_levels, [mean_last_5_years, std_last_5_years, np.nanmean, np.nanstd, lag1, lag2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lags.head()\n",
    "# stats.head()\n",
    "# doy_stats.head() #also includes lags\n",
    "# diff_lags.head()\n",
    "# diff_lags_stats.head()\n",
    "\n",
    "# check indexes are same\n",
    "def check_same_idxs(dfs):\n",
    "    first_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        if not first_df.index.equals(df.index):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# feature_dfs = (lags, stats, doy_stats, diff_lags, diff_lags_stats)\n",
    "# if check_same_idxs(feature_dfs):\n",
    "#     all_features = pd.concat(feature_dfs, axis=1)\n",
    "# else:\n",
    "#     raise ValueError(\"dfs have different indexes, cant concatenate\")\n",
    "\n",
    "# all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разумеется, нужно добавить сами предсказываемые значения\n",
    "\n",
    "# water_levels.rename(columns={\"max_level\": \"target\"}, inplace=True)\n",
    "# all_features = all_features.merge(water_levels, left_index=True, right_index=True)\n",
    "# all_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add lon lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = pd.read_csv(os.path.join(data_dir, \"hydro_features.csv\"))\n",
    "# all_features[\"date\"] = pd.to_datetime(all_features[\"date\"])\n",
    "# all_features.set_index([\"id\", \"date\"], inplace=True)\n",
    "# all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydro_coords = pd.read_csv(data_dir + \"hydro_posts_coords.csv\")\n",
    "# hydro_coords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = all_features.reset_index().merge(hydro_coords, on=\"id\", how=\"left\")\n",
    "# all_features.set_index([\"id\", \"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract calendar features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = all_features.index.get_level_values(\"date\")\n",
    "# doy = date.dayofyear\n",
    "# all_features[\"doy\"] = doy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_doy(df):\n",
    "    date = df.reset_index()[\"date\"]\n",
    "    return date.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_diff_features(df):\n",
    "    diff_lags = extract_features(df, diff_lag, [7])\n",
    "    diff_lags.index = df.index\n",
    "    \n",
    "    diff_lags_stats = calc_diff_lags_stats(diff_lags, [np.nanmean, np.nanstd])\n",
    "    \n",
    "    features = pd.concat([diff_lags, diff_lags_stats], axis=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_features_concat(features_dfs):\n",
    "    if check_same_idxs(feature_dfs):\n",
    "        return pd.concat(feature_dfs, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"dfs have different indexes, cant concatenate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features_with_coords(features, coords):\n",
    "    merged = features.reset_index().merge(coords, on=\"id\", how=\"left\")\n",
    "    merged.set_index([\"id\", \"date\"], inplace=True)\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def water_levels_features(water_levels):\n",
    "    water_levels = fill_missing_dates(water_levels)\n",
    "    \n",
    "    stat_config = [\n",
    "    [np.nanmean, 1, 7],\n",
    "    [np.nanmean, 1, 30],\n",
    "    [np.nanstd, 1, 30],\n",
    "    \n",
    "    [np.nanmax, 1, 7],\n",
    "    [np.nanmin, 1, 7],\n",
    "    \n",
    "    [np.nanmax, 1, 30],\n",
    "    [np.nanmin, 1, 30]\n",
    "    ]\n",
    "    stats = extract_features(water_levels, stat, stat_config)\n",
    "    lags = extract_features(water_levels, lag, np.arange(1, 8))\n",
    "    \n",
    "    diff_features = extract_diff_features(water_levels)\n",
    "    doy_stats = past_years_stats(water_levels, [mean_last_5_years, std_last_5_years, np.nanmean, np.nanstd, lag1, lag2])\n",
    "    doy = df_doy(all_features)\n",
    "    \n",
    "    all_features = safe_features_concat([lags, stats, diff_features, doy_stats, water_levels, doy])\n",
    "    \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hydro_feature_extraction(water_levels, hydro_coords,):\n",
    "    all_features = water_levels_features(water_levels)\n",
    "    all_features = merge_features_with_coords(all_features, hydro_coords)\n",
    "    \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n",
      "end!\n",
      "start extracting\n"
     ]
    }
   ],
   "source": [
    "all_features = hydro_feature_extraction(water_levels, hydro_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features.to_csv(os.path.join(data_dir, \"hydro_features.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def water_levels_features_latest_date(water_levels):\n",
    "#     \"\"\"Extracting features only for last date in water_levels,\n",
    "#     used for step predict.\"\"\"\n",
    "#     water_levels = fill_missing_dates(water_levels)\n",
    "    \n",
    "#     stat_config = [\n",
    "#     [np.nanmean, 1, 7],\n",
    "#     [np.nanmean, 1, 30],\n",
    "#     [np.nanstd, 1, 30],\n",
    "    \n",
    "#     [np.nanmax, 1, 7],\n",
    "#     [np.nanmin, 1, 7],\n",
    "    \n",
    "#     [np.nanmax, 1, 30],\n",
    "#     [np.nanmin, 1, 30]\n",
    "#     ]\n",
    "#     water_levels_last_31_days = n_latest_dates(water_levels, 31)\n",
    "#     stats = extract_features(water_levels_last_31_days, stat, stat_config)\n",
    "    \n",
    "#     water_levels_last_9_days = n_latest_dates(water_levels, 9)\n",
    "#     diff_features = extract_diff_features(water_levels_last_9_days)\n",
    "#     lags = extract_features(water_levels, lag, np.arange(1, 8))\n",
    "    \n",
    "#     doy_stats = past_years_stats(water_levels, [mean_last_5_years, std_last_5_years, np.nanmean, np.nanstd, lag1, lag2])\n",
    "#     doy = df_doy(all_features)\n",
    "    \n",
    "#     all_features = safe_features_concat([lags, stats, diff_features, doy_stats, water_levels, doy])\n",
    "#     all_features = keep_latest_date(all_features)\n",
    "#     return all_features\n",
    "                                 \n",
    "    \n",
    "\n",
    "# def n_latest_dates(df, n):\n",
    "#     dates = df.reset_index()[\"date\"]\n",
    "#     last_n_uniq_dates = sorted(dates.unique())[-n:]\n",
    "    \n",
    "#     mask_last_n_dates = dates.isin(last_n_uniq_dates).values\n",
    "    \n",
    "#     return df[mask_last_n_dates]\n",
    "\n",
    "# def keep_latest_date(df):\n",
    "#     dates = df.reset_index()[\"date\"]\n",
    "#     latest_date = dates.max()\n",
    "    \n",
    "#     mask_latest_date = dates.values == latest_date\n",
    "    \n",
    "#     return df[mask_latest_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def last_day_hydro_feature_extraction(water_levels, hydro_coords):\n",
    "#     all_features = water_levels_features_latest_date(water_levels)\n",
    "#     all_features = merge_features_with_coords(all_features, hydro_coords)\n",
    "    \n",
    "#     return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_day = last_day_hydro_feature_extraction(water_levels, hydro_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### проверяем, что всё извлеклось мы хотели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_example = stats.loc[5019]\n",
    "# st_example.iloc[:10] #first values\n",
    "# st_example[st_example.index.year == 1990].iloc[:10] # values from n year\n",
    "\n",
    "# st_example = water_levels.loc[5019]\n",
    "# st_example.iloc[:10] #first values\n",
    "# st_example[st_example.index.year == 1990].iloc[:10] # values from second year\n",
    "# st_example[(st_example.index.month == 1) & (st_example.index.day == 1)].iloc[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
