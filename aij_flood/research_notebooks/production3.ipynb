{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import features\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../datasets/\"\n",
    "s2m_path = \"./handmade_s2m.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"past_features.csv\", index_col=[0, 1])\n",
    "target = pd.read_csv(\"past_target.csv\", index_col=[0, 1])\n",
    "\n",
    "X = features.utils.reduce_memory_usage(X)\n",
    "target = features.utils.reduce_memory_usage(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(X.columns)\n",
    "cols[8: 8+7] = [f\"lag_{i}\" for i in range(1, 8)]\n",
    "\n",
    "X.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stationNumber</th>\n",
       "      <th>water_levels_nanmean_1_7</th>\n",
       "      <th>water_levels_nanmean_1_30</th>\n",
       "      <th>water_levels_nanstd_1_30</th>\n",
       "      <th>water_levels_nanmax_1_7</th>\n",
       "      <th>water_levels_nanmin_1_7</th>\n",
       "      <th>water_levels_nanmax_1_30</th>\n",
       "      <th>water_levels_nanmin_1_30</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>maximumTemperatureOverPeriodSpecified_nanmean_1_7</th>\n",
       "      <th>cloudCoverTotal_diff_nanmean_1_7</th>\n",
       "      <th>windSpeed_diff_nanmean_1_7</th>\n",
       "      <th>totalAccumulatedPrecipitation_diff_nanmean_1_7</th>\n",
       "      <th>soilTemperature_diff_nanmean_1_7</th>\n",
       "      <th>airTemperature_diff_nanmean_1_7</th>\n",
       "      <th>relativeHumidity_diff_nanmean_1_7</th>\n",
       "      <th>pressureReducedToMeanSeaLevel_diff_nanmean_1_7</th>\n",
       "      <th>windAngleX_diff_nanmean_1_7</th>\n",
       "      <th>windAngleY_diff_nanmean_1_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5001</th>\n",
       "      <th>1984-01-01</th>\n",
       "      <td>31707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-02</th>\n",
       "      <td>31707</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.424999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>-0.299988</td>\n",
       "      <td>-0.121696</td>\n",
       "      <td>-0.077529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 stationNumber  water_levels_nanmean_1_7  \\\n",
       "id   date                                                  \n",
       "5001 1984-01-01          31707                       NaN   \n",
       "     1984-01-02          31707                     258.0   \n",
       "\n",
       "                 water_levels_nanmean_1_30  water_levels_nanstd_1_30  \\\n",
       "id   date                                                              \n",
       "5001 1984-01-01                        NaN                       NaN   \n",
       "     1984-01-02                      258.0                       NaN   \n",
       "\n",
       "                 water_levels_nanmax_1_7  water_levels_nanmin_1_7  \\\n",
       "id   date                                                           \n",
       "5001 1984-01-01                      NaN                      NaN   \n",
       "     1984-01-02                    258.0                    258.0   \n",
       "\n",
       "                 water_levels_nanmax_1_30  water_levels_nanmin_1_30  lag_1  \\\n",
       "id   date                                                                    \n",
       "5001 1984-01-01                       NaN                       NaN    NaN   \n",
       "     1984-01-02                     258.0                     258.0  258.0   \n",
       "\n",
       "                 lag_2  ...  \\\n",
       "id   date               ...   \n",
       "5001 1984-01-01    NaN  ...   \n",
       "     1984-01-02    NaN  ...   \n",
       "\n",
       "                 maximumTemperatureOverPeriodSpecified_nanmean_1_7  \\\n",
       "id   date                                                            \n",
       "5001 1984-01-01                                                NaN   \n",
       "     1984-01-02                                         -17.424999   \n",
       "\n",
       "                 cloudCoverTotal_diff_nanmean_1_7  windSpeed_diff_nanmean_1_7  \\\n",
       "id   date                                                                       \n",
       "5001 1984-01-01                               NaN                         NaN   \n",
       "     1984-01-02                               1.0                   -1.333333   \n",
       "\n",
       "                 totalAccumulatedPrecipitation_diff_nanmean_1_7  \\\n",
       "id   date                                                         \n",
       "5001 1984-01-01                                             NaN   \n",
       "     1984-01-02                                             0.0   \n",
       "\n",
       "                 soilTemperature_diff_nanmean_1_7  \\\n",
       "id   date                                           \n",
       "5001 1984-01-01                               NaN   \n",
       "     1984-01-02                               1.0   \n",
       "\n",
       "                 airTemperature_diff_nanmean_1_7  \\\n",
       "id   date                                          \n",
       "5001 1984-01-01                              NaN   \n",
       "     1984-01-02                         1.666667   \n",
       "\n",
       "                 relativeHumidity_diff_nanmean_1_7  \\\n",
       "id   date                                            \n",
       "5001 1984-01-01                                NaN   \n",
       "     1984-01-02                          -4.666667   \n",
       "\n",
       "                 pressureReducedToMeanSeaLevel_diff_nanmean_1_7  \\\n",
       "id   date                                                         \n",
       "5001 1984-01-01                                             NaN   \n",
       "     1984-01-02                                       -0.299988   \n",
       "\n",
       "                 windAngleX_diff_nanmean_1_7  windAngleY_diff_nanmean_1_7  \n",
       "id   date                                                                  \n",
       "5001 1984-01-01                          NaN                          NaN  \n",
       "     1984-01-02                    -0.121696                    -0.077529  \n",
       "\n",
       "[2 rows x 92 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5001</th>\n",
       "      <th>1984-01-01</th>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-02</th>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target\n",
       "id   date              \n",
       "5001 1984-01-01   258.0\n",
       "     1984-01-02   255.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)\n",
    "target.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find nearest and most corr points and concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_features = features.groupby(\"date\").agg(np.nanmean)\n",
    "# global_target = target.groupby(\"date\").agg(np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesValFoldRetriever:\n",
    "    def __init__(self, X, labels, nfolds=12, val_width=30):\n",
    "        self.X = X\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.dates = self.X.index.get_level_values(\"date\")\n",
    "        self.uniq_dates = sorted(self.dates.unique())\n",
    "        self.unique_dates_num = len(self.uniq_dates)\n",
    "        \n",
    "        self.nfolds = nfolds\n",
    "        self.val_width = val_width\n",
    "        \n",
    "        self.set_folds_periods()\n",
    "        \n",
    "        \n",
    "    def set_folds_periods(self):\n",
    "        self.train_masks = []\n",
    "        self.val_masks = []\n",
    "        \n",
    "        train_start = 0\n",
    "        last_idx = self.unique_dates_num - 1\n",
    "        \n",
    "        for fold_idx in range(self.nfolds):\n",
    "            folds_till_end = self.nfolds - fold_idx + 1\n",
    "            train_end = last_idx - folds_till_end * self.val_width\n",
    "            \n",
    "            val_start = train_end\n",
    "            val_end = val_start + self.val_width\n",
    "            \n",
    "            train_dates = self.uniq_dates[train_start: train_end]\n",
    "            val_dates = self.uniq_dates[val_start: val_end]\n",
    "            \n",
    "            train_date_mask = self.dates.isin(train_dates)\n",
    "            val_date_mask = self.dates.isin(val_dates)\n",
    "            \n",
    "            self.train_masks.append(train_date_mask)\n",
    "            self.val_masks.append(val_date_mask)\n",
    "        \n",
    "#     def __next__(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        for fold_idx in range(self.nfolds):\n",
    "            train_period = self.train_masks[fold_idx]\n",
    "            val_period = self.val_masks[fold_idx]\n",
    "            \n",
    "            train_X, train_labels = self.X[train_period], self.labels[train_period]\n",
    "            val_X, val_labels = self.X[val_period], self.labels[val_period]\n",
    "            \n",
    "            yield train_X, train_labels, val_X, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidator:\n",
    "    def __init__(self, folds, model, metric):\n",
    "        \"\"\"\n",
    "        :param folds: iterable containing t_x, t_y, v_x, v_y\"\"\"\n",
    "        self.folds = folds\n",
    "        self.model = model\n",
    "        self.metrics = metric\n",
    "        \n",
    "    def run_cv(self):\n",
    "        self.metrics_vals = {f\"{metric.__name__}\": [] for metric in self.metrics}\n",
    "        \n",
    "        for fold_num, (xtrain, ytrain, xval, yval) in enumerate(self.folds):\n",
    "            print(f\"starting {fold_num} fold\")\n",
    "#             print(xtrain, ytrain)\n",
    "            model.fit(xtrain, ytrain)\n",
    "            val_preds = model.predict(xval)\n",
    "            \n",
    "            for metric in self.metrics:\n",
    "                metric_val = metric(val_preds, yval)\n",
    "                self.metrics_vals[f\"{metric.__name__}\"].append(metric_val)\n",
    "            \n",
    "        return self.metrics_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StationModelsManager:\n",
    "    \"\"\"creates StattionFitters for every station_id from __init__, \n",
    "    Cat train and evaluate these models, return final metric for all stations\"\"\"\n",
    "    def __init__(self, station_ids, models):\n",
    "        self.station_ids = station_ids\n",
    "        self.models = {}\n",
    "        \n",
    "        for id_stat, model in zip(self.station_ids, models):\n",
    "            self.models[id_stat] = model\n",
    "        \n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, target: pd.DataFrame):\n",
    "        \n",
    "        for station_id, model in self.models.items():\n",
    "            station_X = self._get_station_data(X, station_id)\n",
    "            station_target = self._get_station_data(target, station_id)\n",
    "            model.fit(station_X, station_target)\n",
    "            \n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        answers = np.zeros(len(X))\n",
    "        \n",
    "        for station_id, model in self.models.items():\n",
    "            station_X = self._get_station_data(X, station_id)\n",
    "            station_model = self.models[station_id]\n",
    "            preds = station_model.predict(station_X)\n",
    "            \n",
    "            curr_station_mask = self._curr_station_mask(X, station_id)\n",
    "            answers[curr_station_mask] = preds\n",
    "            \n",
    "        return answers\n",
    "            \n",
    "    def _get_station_data(self, df, station_id):\n",
    "        station_mask = self._curr_station_mask(df, station_id)\n",
    "        df_station = df.iloc[station_mask]\n",
    "        return df_station\n",
    "    \n",
    "    def _curr_station_mask(self, df, station_id):\n",
    "        id_col = df.reset_index()[\"id\"]\n",
    "        station_mask = (id_col == station_id).values\n",
    "        \n",
    "        return station_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LgbModel:\n",
    "    \"\"\"Controlles process of training model on data from single station\"\"\"\n",
    "    def __init__(self, model_config, fobj):\n",
    "        self.lgb_param = model_config\n",
    "        self.fobj = fobj\n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        dataset = lgb.Dataset(x, y)\n",
    "        self.model = lgb.train(self.lgb_param, dataset, fobj=self.fobj)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flood_mse_fobj(y_pred, y, alpha=1.5):\n",
    "    y = y.get_label()\n",
    "    \n",
    "#     print(\"max y train\", np.max(y))\n",
    "#     print(\"max y pred\", np.max(y_pred))\n",
    "    \n",
    "    deviation = (y_pred - y) ** 2\n",
    "    gradient = 2 * (y_pred - y)\n",
    "    hessian = np.sign(deviation) * 2\n",
    "    \n",
    "    gradient[gradient < 0] *= alpha\n",
    "    hessian[hessian < 0] *= alpha\n",
    "    \n",
    "    return gradient, hessian\n",
    "\n",
    "def flood_mse_feval(y_pred, y, alpha=1.5):\n",
    "    y = y[\"target\"].values\n",
    "    deviation = (y_pred - y) ** 2\n",
    "    deviation[deviation < 0] *= alpha\n",
    "    \n",
    "    return np.mean(deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge with nearest and most corr stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_and_nearest = pd.read_csv(\"corrs_and_dists.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor_corr_and_nearest(corr_and_nearest, id_idx):\n",
    "    best_corr_nan_mask = corr_and_nearest[\"best_corr_post\"].isna()\n",
    "\n",
    "    fill_vals = corr_and_nearest.loc[best_corr_nan_mask].index \n",
    "    corr_and_nearest.loc[best_corr_nan_mask, \"best_corr_post\"] = fill_vals\n",
    "    \n",
    "    best_corr_map = corr_and_nearest[\"best_corr_post\"].to_dict()\n",
    "    id2bestcorr_id = id_idx.map(best_corr_map)\n",
    "    \n",
    "    nearest_map = corr_and_nearest[\"nearest_post\"].to_dict()\n",
    "    id2nearest_id = id_idx.map(nearest_map)\n",
    "    \n",
    "    return id2bestcorr_id, id2nearest_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_corr_nearest(X, corr_and_nearest):\n",
    "    id2bestcorr_id, id2nearest_id = preprocessor_corr_and_nearest(corr_and_nearest, X.reset_index()[\"id\"])\n",
    "\n",
    "    X2 = X.copy()\n",
    "\n",
    "    new_cols = [f\"corr_{colname}\" for colname in X2.columns]\n",
    "    X2.columns = new_cols\n",
    "\n",
    "    X.reset_index(inplace=True)\n",
    "    X = X.merge(X2, left_on=[id2bestcorr_id, \"date\"], right_on=[\"id\", \"date\"], how=\"left\")\n",
    "\n",
    "    new_cols = [f\"nearest_{colname}\" for colname in X2.columns]\n",
    "    X2.columns = new_cols\n",
    "\n",
    "    X = X.merge(X2, left_on=[id2nearest_id, \"date\"], right_on=[\"id\", \"date\"], how=\"left\")\n",
    "    \n",
    "    X.set_index([\"id\", \"date\"], inplace=True)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_notnan_mask = target.notna().values\n",
    "X, target = X[target_notnan_mask], target[target_notnan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_station_ids = [6005, 6022, 6027, 5004, 5012, 5024, 5805]\n",
    "# target_stations_mask = X.reset_index()[\"id\"].isin(target_station_ids).values\n",
    "\n",
    "# X = X[target_stations_mask]\n",
    "# target = target[target_stations_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 0 fold\n",
      "starting 1 fold\n",
      "starting 2 fold\n",
      "starting 3 fold\n",
      "starting 4 fold\n",
      "starting 5 fold\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'flood_mse_feval': [12043.230755168724,\n",
       "  758.6412185728067,\n",
       "  413.94074889485904,\n",
       "  240.77170999038665,\n",
       "  250.42788422392155,\n",
       "  459.7981402363564],\n",
       " 'mean_absolute_error': [18.974347253693363,\n",
       "  15.741925569294763,\n",
       "  12.21883321020326,\n",
       "  9.734233721467517,\n",
       "  8.211703517986244,\n",
       "  11.896107156943005]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_param = {\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "target_station_ids = [6005, 6022, 6027, 5004, 5012, 5024, 5805]\n",
    "target_stations_mask = X.reset_index()[\"id\"].isin(target_station_ids).values\n",
    "\n",
    "models = []\n",
    "for idx in range(len(target_station_ids)):\n",
    "    models.append(LgbModel(lgb_param, flood_mse_fobj))\n",
    "    \n",
    "model = StationModelsManager(target_station_ids, models)   \n",
    "\n",
    "folds_retriever = TimeSeriesValFoldRetriever(X[target_stations_mask], target[target_stations_mask], nfolds=6, val_width=31)\n",
    "\n",
    "cross_val = CrossValidator(folds_retriever, model, [flood_mse_feval, mae])\n",
    "\n",
    "cross_val.run_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.79619173826469"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "48.59151238828831"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val.metrics_vals[\"mean_absolute_error\"])\n",
    "np.sqrt(np.mean(cross_val.metrics_vals[\"flood_mse_feval\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.models[6005].model.feature_importance()\n",
    "importances = pd.Series(feature_importance, index=X.columns)\n",
    "\n",
    "n_features = 20\n",
    "\n",
    "top_n_features = list(importances.sort_values(ascending=False).iloc[:n_features].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top_n_features.pkl\", \"rb\") as f:\n",
    "    top_n_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[top_n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merge_corr_nearest(X, corr_and_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_station_ids = [6005, 6022, 6027, 5004, 5012, 5024, 5805]\n",
    "target_stations_mask = X.reset_index()[\"id\"].isin(target_station_ids).values\n",
    "\n",
    "X = X[target_stations_mask]\n",
    "target = target[target_stations_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 0 fold\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5fb4ce8061a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcross_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds_retriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mflood_mse_feval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcross_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-fb7abddaa54e>\u001b[0m in \u001b[0;36mrun_cv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"starting {fold_num} fold\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#             print(xtrain, ytrain)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-380654f223e6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, target)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mstation_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_station_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mstation_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_station_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstation_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-14a67c459b2b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgb_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/aij20-flood-lIcseS5N/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/aij20-flood-lIcseS5N/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"none\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2379\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__boost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__boost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/aij20-flood-lIcseS5N/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__boost\u001b[0;34m(self, grad, hess)\u001b[0m\n\u001b[1;32m   2409\u001b[0m                              .format(len(grad), len(hess)))\n\u001b[1;32m   2410\u001b[0m         \u001b[0mis_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2411\u001b[0;31m         _safe_call(_LIB.LGBM_BoosterUpdateOneIterCustom(\n\u001b[0m\u001b[1;32m   2412\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgb_param = {\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "target_station_ids = [6005, 6022, 6027, 5004, 5012, 5024, 5805]\n",
    "target_stations_mask = X.reset_index()[\"id\"].isin(target_station_ids).values\n",
    "\n",
    "models = []\n",
    "for idx in range(len(target_station_ids)):\n",
    "    models.append(LgbModel(lgb_param, flood_mse_fobj))\n",
    "    \n",
    "model = StationModelsManager(target_station_ids, models) \n",
    "\n",
    "folds_retriever = TimeSeriesValFoldRetriever(X, target, nfolds=6, val_width=31)\n",
    "\n",
    "cross_val = CrossValidator(folds_retriever, model, [flood_mse_feval, mae])\n",
    "\n",
    "cross_val.run_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val.metrics_vals[\"mean_absolute_error\"])\n",
    "np.sqrt(np.mean(cross_val.metrics_vals[\"flood_mse_feval\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station, model in model.models.items():\n",
    "    with open(f\"../../model_{station}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<module 'features' from '../features/__init__.py'>,\n",
       " <module 'features.meteo' from '../features/meteo/__init__.py'>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(features), reload(features.meteo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _build_general_df(self, dfs):\n",
    "#     ids = list(self.meteo_coords[\"station_id\"])\n",
    "\n",
    "#     for station_id, df in zip(ids, dfs):\n",
    "#         df[\"id\"] = station_id\n",
    "\n",
    "#     general_df = pd.concat(dfs, axis=0)\n",
    "#     return general_df\n",
    "\n",
    "\n",
    "# meteo_forecast_loader._build_general_df = _build_general_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get data station_id     31725\n",
      "lon           133.83\n",
      "lat             48.6\n",
      "Name: 0, dtype: object\n",
      "got data 21.934844493865967\n",
      "get data station_id      31735\n",
      "lon           135.188\n",
      "lat           48.5281\n",
      "Name: 1, dtype: object\n",
      "got data 22.21863842010498\n",
      "parsing\n",
      "parsing\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_build_general_df() missing 1 required positional argument: 'dfs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-540e203c3905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeteo_forecast_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeded_meteo_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/aij20-flood/aij_flood/features/meteo/meteo_loaders.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, needed_meteo_ids)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mpoints_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_general_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_dates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_normal_colnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _build_general_df() missing 1 required positional argument: 'dfs'"
     ]
    }
   ],
   "source": [
    "forecast = meteo_forecast_loader.load(needed_meteo_ids) #[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top_n_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(top_n_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models_manager.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'flood_mse_fobj' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1a3a7cc4760d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models_manager.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"top_n_features.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtop_n_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'flood_mse_fobj' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "with open(\"models_manager.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f) \n",
    "    \n",
    "with open(\"top_n_features.pkl\", \"rb\") as f:\n",
    "    top_n_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date_fmt = \"%Y-%m-%d\"\n",
    "test_start_date, test_end_date = datetime.strptime(\"2020-10-24\", test_date_fmt), datetime.strptime(\"2020-11-04\", test_date_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_parser = features.meteo.ForecastParser()\n",
    "forecast_preprocessor = features.meteo.ForecastMeteoPreprocessor()\n",
    "coords_builder = features.CoordsBuilder(data_dir + \"processed_data/asunp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_forecast_src = np.array([(\"Total_cloud_cover_entire_atmosphere_Mixed_intervals_Average\", \"cloudCoverTotal\"),\n",
    "                        ('u-component_of_wind_height_above_ground', \"windAngleX\"), \n",
    "                        ('v-component_of_wind_height_above_ground', \"windAngleY\"),\n",
    "                        ('Wind_speed_gust_surface', \"windSpeed\"), \n",
    "                        ('Total_precipitation_surface_Mixed_intervals_Accumulation', \"totalAccumulatedPrecipitation\"), \n",
    "                        (\"Temperature_height_above_ground\", 'airTemperature'), \n",
    "                        ('Maximum_temperature_height_above_ground_Mixed_intervals_Maximum', 'maximumTemperatureOverPeriodSpecified'), \n",
    "                        ('Minimum_temperature_height_above_ground_Mixed_intervals_Minimum', 'minimumTemperatureAtHeightAndOverPeriodSpecified'),\n",
    "                        ('Temperature_surface', 'soilTemperature'), \n",
    "                        ('Relative_humidity_height_above_ground', 'relativeHumidity'), \n",
    "                        ('Pressure_height_above_ground', 'pressure'), \n",
    "                        ('Pressure_reduced_to_MSL_msl', 'pressureReducedToMeanSeaLevel'),\n",
    "                        (\"Dewpoint_temperature_height_above_ground\", \"dewpointTemperature\")\n",
    "                       ])\n",
    "\n",
    "retrieved_vars = list(name_forecast_src[:, 1])\n",
    "varnames_table = pd.DataFrame(name_forecast_src, columns=[\"forecast\", \"src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_forecast_loader = features.meteo.ForecastMeteoLoader(test_start_date, test_end_date, coords_builder, \n",
    "                                                          retrieved_vars, varnames_table, forecast_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2m = pd.read_csv(s2m_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_meteo_ids(X):\n",
    "    stations = X.reset_index()[\"id\"].unique()\n",
    "    s2m.set_index(\"station_id\", inplace=True)\n",
    "    print(s2m.reset_index().dtypes)\n",
    "    \n",
    "    needed_meteo = []\n",
    "    for station in list(stations):\n",
    "        needed_meteo.append(s2m.loc[station, \"meteo_id\"])\n",
    "        \n",
    "    return needed_meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station_id    float64\n",
      "meteo_id        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "needed_meteo_ids = get_needed_meteo_ids(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
