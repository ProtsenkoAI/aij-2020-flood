{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../working_data/\"\n",
    "SRC_DATA_DIR = \"../datasets/processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBuilder:\n",
    "    # TODO: функции доступа к date и id, тк сейчас они то в колоноках,\n",
    "    # то в индексах, так что вылетают рандомные ошибки\n",
    "    def __init__(self, hydro, meteo, s2m_dict):\n",
    "        self.hydro = self.prepare_df(hydro)\n",
    "        self.meteo = self.prepare_df(meteo)\n",
    "        self.s2m_dict = s2m_dict\n",
    "        \n",
    "    def prepare_df(self, df):\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        first2cols = list(df.columns[:2])\n",
    "        df.set_index(first2cols, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def build(self):\n",
    "        self.fill_missing_dates()\n",
    "        self.merged = self.merge_parts()\n",
    "        self.extract_merged_x_y()\n",
    "        \n",
    "        return self.features, self.target\n",
    "    \n",
    "    def fill_missing_dates(self):\n",
    "        min_date, max_date = self.min_max_data_date()\n",
    "        \n",
    "        new_hydro_idx = self.create_all_dates_index(self.hydro, min_date, max_date)\n",
    "        new_meteo_idx = self.create_all_dates_index(self.meteo, min_date, max_date)\n",
    "        \n",
    "        fill_val = np.nan\n",
    "        self.hydro = self.hydro.reindex(new_hydro_idx, fill_value=fill_val)\n",
    "        self.meteo = self.meteo.reindex(new_meteo_idx, fill_value=fill_val)\n",
    "    \n",
    "    def min_max_data_date(self):\n",
    "        dates_hydro = self.hydro.index.get_level_values(\"date\")\n",
    "        dates_meteo = self.meteo.index.get_level_values(\"date\")\n",
    "        \n",
    "        min_date = min(dates_hydro.min(), dates_meteo.min())\n",
    "        max_date = max(dates_hydro.max(), dates_meteo.max())\n",
    "        \n",
    "        return min_date, max_date\n",
    "    \n",
    "    def create_all_dates_index(self, df, min_date, max_date):\n",
    "        id_idxs = df.index.get_level_values(0).unique()\n",
    "        new_date_index = pd.date_range(min_date, max_date, name=\"date\")\n",
    "        \n",
    "        all_dates_index = pd.MultiIndex.from_product([id_idxs, new_date_index])\n",
    "        \n",
    "        return all_dates_index\n",
    "    \n",
    "    def merge_parts(self):\n",
    "        nearest_meteo_id = self.hydro_to_meteo_map_col()\n",
    "        \n",
    "        hydro = self.hydro.reset_index()\n",
    "        meteo = self.meteo\n",
    "\n",
    "        merged = hydro.merge(meteo, left_on=[nearest_meteo_id, \"date\"], right_on=[\"stationNumber\", \"date\"], how=\"left\")\n",
    "        merged.set_index([\"id\", \"date\"], inplace=True)\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def hydro_to_meteo_map_col(self):\n",
    "        hydro_id = self.hydro.index.get_level_values(\"id\")\n",
    "        hydro_nearest_meteo = hydro_id.map(self.s2m_dict)\n",
    "        \n",
    "        return hydro_nearest_meteo\n",
    "    \n",
    "    def extract_merged_x_y(self):\n",
    "        feature_cols = list(self.merged.columns)\n",
    "        feature_cols.remove(\"target\")\n",
    "\n",
    "        self.features = self.merged[feature_cols]\n",
    "        self.target = self.merged[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro = pd.read_csv(DATA_DIR + \"hydro_features.csv\")\n",
    "meteo = pd.read_csv(DATA_DIR + \"meteo_features.csv\")\n",
    "\n",
    "hydro = utils.reduce_memory_usage(hydro)\n",
    "meteo = utils.reduce_memory_usage(meteo)\n",
    "\n",
    "s2m = pd.read_csv(DATA_DIR + \"handmade_s2m.csv\", index_col=0)\n",
    "s2m_dict = s2m.to_dict()[\"meteo_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = DataBuilder(hydro, meteo, s2m_dict)\n",
    "features, target = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hydro, meteo, builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop objects where target is none\n",
    "target_nan_mask = target.notna()\n",
    "features, target = features[target_nan_mask], target[target_nan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DatasetRetriever(Dataset):\n",
    "#     def __init__(self, features, target):\n",
    "#         super().__init__()\n",
    "#         self.features = features\n",
    "#         self.target = target\n",
    "        \n",
    "#     def __getitem__(self, index: int):\n",
    "#         obj_features = self.features.iloc[index]\n",
    "#         obj_target = self.target.iloc[index]\n",
    "        \n",
    "#         return obj_features, obj_target\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.features)\n",
    "    \n",
    "# data_retr = DatasetRetriever(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stationNumber</th>\n",
       "      <th>max_level_lag_1</th>\n",
       "      <th>max_level_lag_2</th>\n",
       "      <th>max_level_lag_3</th>\n",
       "      <th>max_level_lag_4</th>\n",
       "      <th>max_level_lag_5</th>\n",
       "      <th>max_level_lag_6</th>\n",
       "      <th>max_level_lag_7</th>\n",
       "      <th>max_level_nanmean_1_7</th>\n",
       "      <th>max_level_nanmean_1_30</th>\n",
       "      <th>...</th>\n",
       "      <th>windAngleY</th>\n",
       "      <th>cloudCoverTotal_diff</th>\n",
       "      <th>windSpeed_diff</th>\n",
       "      <th>totalAccumulatedPrecipitation_diff</th>\n",
       "      <th>soilTemperature_diff</th>\n",
       "      <th>airTemperature_diff</th>\n",
       "      <th>relativeHumidity_diff</th>\n",
       "      <th>pressureReducedToMeanSeaLevel_diff</th>\n",
       "      <th>windAngleX_diff</th>\n",
       "      <th>windAngleY_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5001</th>\n",
       "      <th>1984-01-01</th>\n",
       "      <td>31707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>-0.299988</td>\n",
       "      <td>-0.121696</td>\n",
       "      <td>-0.077529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-02</th>\n",
       "      <td>31707</td>\n",
       "      <td>258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.500000</td>\n",
       "      <td>256.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176777</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.675000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.075005</td>\n",
       "      <td>0.088388</td>\n",
       "      <td>-0.088388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-03</th>\n",
       "      <td>31707</td>\n",
       "      <td>255.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.275009</td>\n",
       "      <td>-0.088388</td>\n",
       "      <td>0.088388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-04</th>\n",
       "      <td>31707</td>\n",
       "      <td>252.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253.250000</td>\n",
       "      <td>253.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673982</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.287491</td>\n",
       "      <td>-0.029073</td>\n",
       "      <td>-0.045636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-01-05</th>\n",
       "      <td>31707</td>\n",
       "      <td>248.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251.399994</td>\n",
       "      <td>251.399994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.117462</td>\n",
       "      <td>-0.042753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6574</th>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>31594</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>27.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422554</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>-3.125000</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.004073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>31594</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.428572</td>\n",
       "      <td>27.066668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530488</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-0.637500</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.537506</td>\n",
       "      <td>0.115898</td>\n",
       "      <td>0.078174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-29</th>\n",
       "      <td>31594</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.571428</td>\n",
       "      <td>26.666666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487316</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.200</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>-0.107146</td>\n",
       "      <td>-0.060620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-30</th>\n",
       "      <td>31594</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.285715</td>\n",
       "      <td>26.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373578</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.412500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.074997</td>\n",
       "      <td>0.026797</td>\n",
       "      <td>0.031376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>31594</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>26.266666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395606</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.512500</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>-1.125000</td>\n",
       "      <td>0.131191</td>\n",
       "      <td>-0.209949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2207865 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 stationNumber  max_level_lag_1  max_level_lag_2  \\\n",
       "id   date                                                          \n",
       "5001 1984-01-01          31707              NaN              NaN   \n",
       "     1984-01-02          31707            258.0              NaN   \n",
       "     1984-01-03          31707            255.0            258.0   \n",
       "     1984-01-04          31707            252.0            255.0   \n",
       "     1984-01-05          31707            248.0            252.0   \n",
       "...                        ...              ...              ...   \n",
       "6574 2018-12-27          31594             21.0             21.0   \n",
       "     2018-12-28          31594             21.0             21.0   \n",
       "     2018-12-29          31594             21.0             21.0   \n",
       "     2018-12-30          31594             21.0             21.0   \n",
       "     2018-12-31          31594             21.0             21.0   \n",
       "\n",
       "                 max_level_lag_3  max_level_lag_4  max_level_lag_5  \\\n",
       "id   date                                                            \n",
       "5001 1984-01-01              NaN              NaN              NaN   \n",
       "     1984-01-02              NaN              NaN              NaN   \n",
       "     1984-01-03              NaN              NaN              NaN   \n",
       "     1984-01-04            258.0              NaN              NaN   \n",
       "     1984-01-05            255.0            258.0              NaN   \n",
       "...                          ...              ...              ...   \n",
       "6574 2018-12-27             23.0             23.0             27.0   \n",
       "     2018-12-28             21.0             23.0             23.0   \n",
       "     2018-12-29             21.0             21.0             23.0   \n",
       "     2018-12-30             21.0             21.0             21.0   \n",
       "     2018-12-31             21.0             21.0             21.0   \n",
       "\n",
       "                 max_level_lag_6  max_level_lag_7  max_level_nanmean_1_7  \\\n",
       "id   date                                                                  \n",
       "5001 1984-01-01              NaN              NaN             258.000000   \n",
       "     1984-01-02              NaN              NaN             256.500000   \n",
       "     1984-01-03              NaN              NaN             255.000000   \n",
       "     1984-01-04              NaN              NaN             253.250000   \n",
       "     1984-01-05              NaN              NaN             251.399994   \n",
       "...                          ...              ...                    ...   \n",
       "6574 2018-12-27             26.0             26.0              23.142857   \n",
       "     2018-12-28             27.0             26.0              22.428572   \n",
       "     2018-12-29             23.0             27.0              21.571428   \n",
       "     2018-12-30             23.0             23.0              21.285715   \n",
       "     2018-12-31             21.0             23.0              21.000000   \n",
       "\n",
       "                 max_level_nanmean_1_30  ...  windAngleY  \\\n",
       "id   date                                ...               \n",
       "5001 1984-01-01              258.000000  ...    0.881546   \n",
       "     1984-01-02              256.500000  ...    0.176777   \n",
       "     1984-01-03              255.000000  ...    0.353553   \n",
       "     1984-01-04              253.250000  ...    0.673982   \n",
       "     1984-01-05              251.399994  ...    0.411700   \n",
       "...                                 ...  ...         ...   \n",
       "6574 2018-12-27               27.366667  ...    0.422554   \n",
       "     2018-12-28               27.066668  ...    0.530488   \n",
       "     2018-12-29               26.666666  ...    0.487316   \n",
       "     2018-12-30               26.466667  ...    0.373578   \n",
       "     2018-12-31               26.266666  ...    0.395606   \n",
       "\n",
       "                 cloudCoverTotal_diff  windSpeed_diff  \\\n",
       "id   date                                               \n",
       "5001 1984-01-01                 1.000       -1.333333   \n",
       "     1984-01-02                -0.250       -0.125000   \n",
       "     1984-01-03                 0.125        0.375000   \n",
       "     1984-01-04                -0.500        0.000000   \n",
       "     1984-01-05                 0.000       -0.375000   \n",
       "...                               ...             ...   \n",
       "6574 2018-12-27                 0.000        0.125000   \n",
       "     2018-12-28                -1.250       -0.250000   \n",
       "     2018-12-29                 1.250        0.250000   \n",
       "     2018-12-30                 0.000       -0.250000   \n",
       "     2018-12-31                -1.250        0.125000   \n",
       "\n",
       "                 totalAccumulatedPrecipitation_diff  soilTemperature_diff  \\\n",
       "id   date                                                                   \n",
       "5001 1984-01-01                                0.00                 1.000   \n",
       "     1984-01-02                                0.00                -0.250   \n",
       "     1984-01-03                                0.00                 0.000   \n",
       "     1984-01-04                                0.00                 0.125   \n",
       "     1984-01-05                                0.00                 0.000   \n",
       "...                                             ...                   ...   \n",
       "6574 2018-12-27                               -0.05                 0.475   \n",
       "     2018-12-28                                0.00                -1.100   \n",
       "     2018-12-29                                0.00                 1.200   \n",
       "     2018-12-30                                0.00                -0.450   \n",
       "     2018-12-31                                0.00                -0.600   \n",
       "\n",
       "                 airTemperature_diff  relativeHumidity_diff  \\\n",
       "id   date                                                     \n",
       "5001 1984-01-01             1.666667              -4.666667   \n",
       "     1984-01-02            -0.675000               1.625000   \n",
       "     1984-01-03             0.412500              -1.000000   \n",
       "     1984-01-04             0.187500              -0.250000   \n",
       "     1984-01-05            -0.050000              -0.250000   \n",
       "...                              ...                    ...   \n",
       "6574 2018-12-27             0.237500              -3.125000   \n",
       "     2018-12-28            -0.637500               2.250000   \n",
       "     2018-12-29             0.825000              -1.000000   \n",
       "     2018-12-30            -0.412500               0.625000   \n",
       "     2018-12-31            -0.512500               1.125000   \n",
       "\n",
       "                 pressureReducedToMeanSeaLevel_diff  windAngleX_diff  \\\n",
       "id   date                                                              \n",
       "5001 1984-01-01                           -0.299988        -0.121696   \n",
       "     1984-01-02                            1.075005         0.088388   \n",
       "     1984-01-03                           -0.275009        -0.088388   \n",
       "     1984-01-04                           -0.287491        -0.029073   \n",
       "     1984-01-05                           -0.250000         0.117462   \n",
       "...                                             ...              ...   \n",
       "6574 2018-12-27                            0.099998         0.001564   \n",
       "     2018-12-28                            0.537506         0.115898   \n",
       "     2018-12-29                            0.937500        -0.107146   \n",
       "     2018-12-30                            1.074997         0.026797   \n",
       "     2018-12-31                           -1.125000         0.131191   \n",
       "\n",
       "                 windAngleY_diff  \n",
       "id   date                         \n",
       "5001 1984-01-01        -0.077529  \n",
       "     1984-01-02        -0.088388  \n",
       "     1984-01-03         0.088388  \n",
       "     1984-01-04        -0.045636  \n",
       "     1984-01-05        -0.042753  \n",
       "...                          ...  \n",
       "6574 2018-12-27         0.004073  \n",
       "     2018-12-28         0.078174  \n",
       "     2018-12-29        -0.060620  \n",
       "     2018-12-30         0.031376  \n",
       "     2018-12-31        -0.209949  \n",
       "\n",
       "[2207865 rows x 96 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training model for single post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesValFold:\n",
    "    def __init__(self, features, labels, nfolds=12, val_width=30):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.dates = self.features.index.get_level_values(\"date\")\n",
    "        self.uniq_dates = sorted(self.dates.unique())\n",
    "        self.unique_dates_num = len(self.uniq_dates)\n",
    "        \n",
    "        self.nfolds = nfolds\n",
    "        self.val_width = val_width\n",
    "        \n",
    "        self.set_folds_periods()\n",
    "        \n",
    "        \n",
    "    def set_folds_periods(self):\n",
    "        self.train_masks = []\n",
    "        self.val_masks = []\n",
    "        \n",
    "        train_start = 0\n",
    "        last_idx = self.unique_dates_num - 1\n",
    "        \n",
    "        for fold_idx in range(self.nfolds):\n",
    "            folds_till_end = self.nfolds - fold_idx + 1\n",
    "            train_end = last_idx - folds_till_end * self.val_width\n",
    "            \n",
    "            val_start = train_end\n",
    "            val_end = val_start + self.val_width\n",
    "            \n",
    "            train_dates = self.uniq_dates[train_start: train_end]\n",
    "            val_dates = self.uniq_dates[val_start: val_end]\n",
    "            \n",
    "            train_date_mask = self.dates.isin(train_dates)\n",
    "            val_date_mask = self.dates.isin(val_dates)\n",
    "            \n",
    "            self.train_masks.append(train_date_mask)\n",
    "            self.val_masks.append(val_date_mask)\n",
    "        \n",
    "#     def __next__(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        for fold_idx in range(self.nfolds):\n",
    "            train_period = self.train_masks[fold_idx]\n",
    "            val_period = self.val_masks[fold_idx]\n",
    "            \n",
    "            train_features, train_labels = self.features[train_period], self.labels[train_period]\n",
    "            val_features, val_labels = self.features[val_period], self.labels[val_period]\n",
    "            \n",
    "            yield train_features, train_labels, val_features, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_fold = TimeSeriesValFold(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ts_fold:\n",
    "    t_x, t_y, v_x, v_y = i\n",
    "#     print(t_x.reset_index()[\"date\"].max())\n",
    "#     print(\"v\", v_x.reset_index()[\"date\"].min())\n",
    "#     print(\"v max\", v_x.reset_index()[\"date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = lgb.Dataset(features.values, target)\n",
    "\n",
    "lgb_param = {\n",
    "    \"objective\": \"regression\",\n",
    "}\n",
    "\n",
    "model = lgb.train(lgb_param, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LgbModel:\n",
    "    \"\"\"Controlles process of training model on data from single station\"\"\"\n",
    "    def __init__(self, model_config):\n",
    "        self.lgb_param = model_config\n",
    "    \n",
    "    def cross_val_score(self, data_loader):\n",
    "        val_scores = []\n",
    "        \n",
    "        for train_x, train_y, val_x, val_y in data_loader:\n",
    "            model = self.fit(train_x, train_y)\n",
    "            val_scores.append(self.validate(val_x, val_y))\n",
    "        \n",
    "        return np.mean(val_scores)\n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        dataset = lgb.Dataset(x, y)\n",
    "        model = lgb.train(self.lgb_param, dataset)\n",
    "        return model\n",
    "        \n",
    "    def validate(self, features, target):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, features):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StationModelsManager:\n",
    "    \"\"\"creates StattionFitters for every station_id from __init__, \n",
    "    Cat train and evaluate these models, return final metric for all stations\"\"\"\n",
    "    def __init__(self, station_ids, model_fitter_class, model_config, data_loader_class):\n",
    "        self.station_ids = station_ids\n",
    "        self.models = {}\n",
    "        self.data_loader_class = data_loader_class\n",
    "        \n",
    "        for id_stat in self.station_ids:\n",
    "#             station_data = self.get_station_data(dataset, id_stat)\n",
    "            model = model_fitter(model_config)\n",
    "            model_loss = self.models[id_stat] = model\n",
    "        \n",
    "    def cross_val_score(self, features: pd.DataFrame, target: pd.DataFrame):\n",
    "        self.check_input_ids(features)\n",
    "        \n",
    "        scores = []\n",
    "        \n",
    "        for station_id, model in self.models.items():\n",
    "            data_loader = self.get_station_data_loader(features, target, station_id)\n",
    "            score = self.models[station_id].cross_val_score(data_loader)\n",
    "            scores.append(score)\n",
    "            \n",
    "        return np.mean(score)\n",
    "    \n",
    "    def fit(self, features: pd.DataFrame, target: pd.DataFrame):\n",
    "        self.check_input_ids(features)\n",
    "        \n",
    "        for station_id, model in self.models.items():\n",
    "            station_features, station_target = self.get_station_data(features, target, station_id)\n",
    "            model.fit(station_features, station_target)\n",
    "            \n",
    "    def validate(self, features: pd.DataFrame, target: pd.DataFrame):\n",
    "        \n",
    "            \n",
    "    def get_station_data_loader(self, features, target, station_id):\n",
    "        station_features, station_target = self.get_station_data(features, target, station_id)\n",
    "        data_loader = self.data_loader_class(station_features, station_target)\n",
    "        return data_loader\n",
    "    \n",
    "    def get_station_data(self, features, target, station_id):\n",
    "        id_col = features.reset_index()[\"id\"]\n",
    "        station_mask = id_col == station_id\n",
    "        station_features = features[station_mask]\n",
    "        station_target = target[station_mask]\n",
    "        \n",
    "        return station_features, station_target\n",
    "    \n",
    "    \n",
    "    def predict(self, features: pd.DataFrame):\n",
    "        # TODO: test it\n",
    "        self.check_input_ids(features)\n",
    "        \n",
    "        answers = np.arange(len(features))\n",
    "        for station_id in predicted_ids.unique():\n",
    "            curr_station_mask = predicted_ids == station_id\n",
    "            station_features = features[curr_station_mask]\n",
    "            \n",
    "            station_model = self.models[station_id]\n",
    "            preds = station_model.predict(station_features)\n",
    "            \n",
    "            answers[curr_station_mask] = preds\n",
    "            \n",
    "        return answers\n",
    "            \n",
    "    def check_input_ids(self, features):\n",
    "        ids = features.reset_index()[\"id\"]\n",
    "        \n",
    "        in_white_list = ids.isin(self.station_ids)\n",
    "        has_wrong_ids = np.sum(in_white_list) > 0\n",
    "        \n",
    "        if has_wrong_ids:\n",
    "            raise ValueError(\"input features contain data from unknown stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
