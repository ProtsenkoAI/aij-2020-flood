{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show every output in cell, not one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "import drop_utils\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", pd.core.common.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module load\n",
    "def meteo_from_dir(dir_path):\n",
    "    meteo = load_meteo_from_dir(dir_path)\n",
    "    meteo = utils.reduce_memory_usage(meteo)\n",
    "    meteo[\"datetime\"] = _build_meteo_datetime(meteo)\n",
    "    meteo = _keep_useful_data(meteo)\n",
    "    \n",
    "    return meteo\n",
    "    \n",
    "    \n",
    "def load_meteo_from_dir(dir_path):\n",
    "    files = _find_csvs(dir_path)\n",
    "    meteo = _load_and_concat_dfs(files, axis=\"index\")\n",
    "    return meteo\n",
    "    \n",
    "def _find_csvs(dir_path):\n",
    "    all_files = _get_dir_files(dir_path)\n",
    "    csv_files = utils.filter_by_substring(all_files, \"csv\")\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "def _get_dir_files(dir_path):\n",
    "    dir_files = []\n",
    "    \n",
    "    for obj_path in os.listdir(dir_path):\n",
    "        obj_full_path = os.path.join(dir_path, obj_path)\n",
    "        if os.path.isfile(obj_full_path):\n",
    "            dir_files.append(obj_full_path)\n",
    "            \n",
    "    return dir_files\n",
    "            \n",
    "    \n",
    "def _load_and_concat_dfs(csv_paths, axis):\n",
    "    dataframes = _load_dfs(csv_paths)\n",
    "    concated_df = pd.concat(dataframes, axis=axis)\n",
    "    \n",
    "    return concated_df\n",
    "\n",
    "def _load_dfs(paths):\n",
    "    dataframes = []\n",
    "    for file_path in paths:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, index_col=0)\n",
    "            dataframes.append(df)\n",
    "        except pd.errors.ParserError:\n",
    "            print(f\"error with {file_path} occured\")\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "\n",
    "def _build_meteo_datetime(df):\n",
    "    datetime_col = _datetime_from_local(df)\n",
    "    gmt_datetime_col = _meteo_datetime_to_gmt(datetime_col)\n",
    "    \n",
    "    return gmt_datetime_col\n",
    "\n",
    "\n",
    "def _datetime_from_local(df):\n",
    "    date_parts = df[[\"localYear\", \"localMonth\", \"localDay\"]]\n",
    "    date_parts.rename(columns={\"localYear\": \"year\", \"localMonth\": \"month\", \"localDay\": \"day\"}, inplace=True)\n",
    "    datetime_col = pd.to_datetime(date_parts) + pd.to_timedelta(df['localTime'], unit=\"hour\")\n",
    "    \n",
    "    return datetime_col\n",
    "\n",
    "\n",
    "def _meteo_datetime_to_gmt(datetime_col):\n",
    "    msk_time_mask = datetime_col.dt.date < datetime(1993,1,1).date()\n",
    "    datetime_col[msk_time_mask] -= timedelta(hours=3)\n",
    "    return datetime_col\n",
    "\n",
    "def _keep_useful_data(meteo):\n",
    "    drop_cols = get_meteo_drop_cols(meteo)\n",
    "    meteo.drop(columns=drop_cols, inplace=True)\n",
    "    \n",
    "    return meteo\n",
    "    \n",
    "    \n",
    "def get_meteo_drop_cols(meteo):\n",
    "    cols = meteo.columns\n",
    "    \n",
    "    drop_cols = get_meteo_source_datetime_features()\n",
    "    drop_cols += utils.filter_by_substring(cols, \"Sign\")\n",
    "    drop_cols += utils.filter_by_substring(cols, \"Quality\")\n",
    "    drop_cols += drop_utils.filter_cols_min_nan_freq(meteo, 0.2)\n",
    "    \n",
    "    return drop_cols\n",
    "\n",
    "\n",
    "def get_meteo_source_datetime_features():\n",
    "    datetime_cols = [\"year\", \"month\", \"day\", \"time\", \"localYear\", \"localMonth\", \"localDay\", \n",
    "                 \"localTimePeriod\", \"timePeriodNum\", \"localTime\", \"tz\", \"startMeteoDay\"]\n",
    "    return datetime_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meteo = meteo_from_dir(meteo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meteo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(df):\n",
    "    df = process_cloud_cover(df)\n",
    "    df = wind_direction_to_x_y(df)\n",
    "    df = drop_cols_unable_to_forecast(df)\n",
    "    df = df.set_index([\"stationNumber\", \"datetime\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_cloud_cover(df):\n",
    "    column = df[\"cloudCoverTotal\"]\n",
    "    column = column.astype(np.float32)\n",
    "    column[column == 12] = 9.5 # согласно README, это \"10\" с просветами\n",
    "    column[column == 11] = 0.05 # следы облаков\n",
    "    column[column == 13] = np.nan # облака невозможно определить\n",
    "    df[\"cloudCoverTotal\"] = column\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def wind_direction_to_x_y(df):\n",
    "    wind_angle_x, wind_value_y = angle_to_x_y(df[\"windDirection\"])\n",
    "    df.drop(columns=\"windDirection\", inplace=True)\n",
    "    \n",
    "    df[\"windAngleX\"] = wind_angle_x\n",
    "    df[\"windAngleY\"] = wind_value_y\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def angle_to_x_y(angles):\n",
    "    out_x, out_y = np.zeros(len(angles)), np.zeros(len(angles))\n",
    "    \n",
    "    not_null_mask = (angles != 0) & (angles != 999)\n",
    "     \n",
    "    #working only with values in range (1, 360]\n",
    "    angles = angles[not_null_mask]\n",
    "    \n",
    "    # from classical wind angles to geometry angles\n",
    "    right_coords_angles = 90 - angles\n",
    "    right_coords_angles[right_coords_angles < 0] += 360\n",
    "    \n",
    "    radians = np.radians(right_coords_angles)\n",
    "    coses, sines = np.cos(radians), np.sin(radians)\n",
    "    \n",
    "    out_x[not_null_mask] = coses\n",
    "    out_y[not_null_mask] = sines\n",
    "    \n",
    "    return out_x, out_y\n",
    "\n",
    "\n",
    "def drop_cols_unable_to_forecast(df):\n",
    "    unable_to_forecast_cols = [\"pastWeather\", \"presentWeather\", \"maximumWindGustSpeed\", \n",
    "                               \"characteristicOfPressureTendency\", \"HourPressureChange3\", 'vapourPressure']\n",
    "    for col in unable_to_forecast_cols:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meteo = preprocess_dataset(meteo)\n",
    "# meteo = meteo.set_index([\"stationNumber\", \"datetime\"])\n",
    "# meteo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meteo_add_differential(meteo):\n",
    "    diff_cols = [\"cloudCoverTotal\", \"windSpeed\", \"totalAccumulatedPrecipitation\", \"soilTemperature\", \"airTemperature\", \n",
    "                        \"relativeHumidity\", \"pressureReducedToMeanSeaLevel\", \"windAngleX\", \"windAngleY\"]\n",
    "    \n",
    "    diff_values = calc_df_differentials(meteo[diff_cols])\n",
    "    meteo = pd.concat([meteo, diff_values], axis=1)\n",
    "    return meteo\n",
    "    \n",
    "\n",
    "\n",
    "def calc_df_differentials(df):\n",
    "    diff_cols = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_name = str(col) + \"_diff\"\n",
    "        diff_val = differential(df[col])\n",
    "        diff_val[diff_val.isna()] = 0 # nans are at first values\n",
    "        \n",
    "        diff_cols[col_name] = diff_val\n",
    "        \n",
    "    new_df = pd.DataFrame.from_dict(diff_cols, orient=\"columns\")\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def differential(ts, step=1):\n",
    "    shifted_ts = ts.shift(step)\n",
    "    return ts - shifted_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meteo = meteo_add_differential(meteo)\n",
    "# meteo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_feature_cols = [\"stationId\"]\n",
    "# feature_cols = pd.Index([col for col in meteo.columns if not col in non_feature_cols])\n",
    "# feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_daily_mean(meteo, feature_cols):\n",
    "    grouped = groupby_station_date(meteo[feature_cols])\n",
    "    daily_mean = grouped.agg(np.nanmean) \n",
    "    return daily_mean\n",
    "    \n",
    "    \n",
    "def groupby_station_date(df):\n",
    "    df = df.reset_index()\n",
    "    df[\"date\"] = df[\"datetime\"].dt.date\n",
    "    grouped = df.groupby(by=[\"stationNumber\", \"date\"])\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "# meteo_daily = agg_daily_mean(meteo)\n",
    "# del meteo\n",
    "# meteo_daily.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meteo_daily.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extraction_config(df_columns):\n",
    "    funcs_and_listcol = []\n",
    "    funcs_and_listcol.append(get_standard_fe_settings(df_columns))\n",
    "    funcs_and_listcol.append(get_minimal_fe_settings(df_columns))\n",
    "        \n",
    "    return create_config(funcs_and_listcol)\n",
    "\n",
    "def get_standard_fe_settings(df_columns):\n",
    "    feature_extraction = [{\"func\": np.nanmean, \"lag\": 1, \"winsize\": 7}, \n",
    "                        {\"func\": np.nanmean, \"lag\": 7, \"winsize\": 30}, \n",
    "                        {\"func\": np.nanstd, \"lag\": 7, \"winsize\": 30}]\n",
    "    \n",
    "    cols = [\"cloudCoverTotal\", \"windSpeed\", \"totalAccumulatedPrecipitation\", \"soilTemperature\",\n",
    "                            \"airTemperature\", \"dewpointTemperature\", \"pressure\", \"pressureReducedToMeanSeaLevel\",\n",
    "                            \"windAngleX\", \"windAngleY\"]\n",
    "    \n",
    "    return feature_extraction, cols\n",
    "\n",
    "\n",
    "def get_minimal_fe_settings(df_columns):\n",
    "    feature_extraction = [{\"func\": np.nanmean, \"lag\": 1, \"winsize\": 7}]\n",
    "    \n",
    "    cols = [\"minimumTemperatureAtHeightAndOverPeriodSpecified\", \"maximumTemperatureOverPeriodSpecified\"]\n",
    "    diff_cols = utils.filter_by_substring(df_columns, \"_diff\")\n",
    "    cols += diff_cols\n",
    "    \n",
    "    return feature_extraction, cols\n",
    "\n",
    "\n",
    "def create_config(funcs_and_listcol):\n",
    "    config = {}\n",
    "    for funcs, cols in funcs_and_listcol:\n",
    "        for col in cols:\n",
    "            config[col] = funcs\n",
    "            \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = create_feature_extraction_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_with_config(df, config):\n",
    "    all_features = {}\n",
    "    \n",
    "    for col, list_agg_settings in config.items():\n",
    "        col_features = agg_col_with_settings(df[col], list_agg_settings)\n",
    "        all_features.update(col_features)\n",
    "        \n",
    "    aggregated_df = pd.DataFrame.from_dict(all_features, orient=\"columns\")\n",
    "    return aggregated_df\n",
    "        \n",
    "def agg_col_with_settings(col, list_aggregations):\n",
    "    agg_features = {}\n",
    "    for agg_settings in list_aggregations:\n",
    "        new_name = create_agg_name(col, agg_settings)\n",
    "        aggregated_col = agg_col(col, agg_settings)\n",
    "        \n",
    "        agg_features[new_name] = aggregated_col\n",
    "        \n",
    "    return agg_features\n",
    "        \n",
    "        \n",
    "def create_agg_name(col, agg_settings):\n",
    "    return col.name + f\"_{agg_settings['func'].__name__}_{agg_settings['lag']}_{agg_settings['winsize']}\"\n",
    "        \n",
    "    \n",
    "def agg_col(col, agg_settings):\n",
    "    func, winsize, lag = agg_settings[\"func\"], agg_settings[\"winsize\"], agg_settings[\"lag\"]\n",
    "    col = col.reset_index(level=1, drop=True)\n",
    "    \n",
    "    grouped_col = col.groupby(by=\"stationNumber\",)\n",
    "    aggregated_col = grouped_col.rolling(winsize, min_periods=1).agg(func)\n",
    "    shifted_col = aggregated_col.shift(lag)\n",
    "    \n",
    "    shifted_col.index = old_index\n",
    "    return shifted_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate_with_config(meteo_daily, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_extract_features_meteo(meteo_dir):\n",
    "    meteo = load_preprocess_meteo(meteo_dir)\n",
    "    meteo_daily = get_daily_meteo(meteo)\n",
    "    aggregated_meteo = agg_meteo(meteo_daily)\n",
    "    \n",
    "    meteo_all_features = pd.concat([aggregated_meteo, meteo_daily], axis=1)\n",
    "    \n",
    "    return meteo_all_features\n",
    "\n",
    "\n",
    "def load_preprocess_meteo(meteo_dir):\n",
    "    meteo = meteo_from_dir(meteo_dir)\n",
    "    meteo = preprocess_dataset(meteo)\n",
    "    meteo = meteo_add_differential(meteo)\n",
    "    \n",
    "    return meteo\n",
    "\n",
    "def get_daily_meteo(meteo):\n",
    "    feature_cols = get_feature_cols(meteo)\n",
    "    meteo_daily = agg_daily_mean(meteo, feature_cols=feature_cols)\n",
    "    \n",
    "    return meteo_daily\n",
    "\n",
    "def agg_meteo(meteo):\n",
    "    config = create_feature_extraction_config(meteo.columns)\n",
    "    aggregated_meteo = aggregate_with_config(meteo, config)\n",
    "    \n",
    "    return aggregated_meteo\n",
    "    \n",
    "\n",
    "def get_feature_cols(meteo):\n",
    "    non_feature_cols = [\"stationId\"]\n",
    "    feature_cols = pd.Index([col for col in meteo.columns if not col in non_feature_cols])\n",
    "    \n",
    "    return feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../\"\n",
    "data_dir = os.path.join(root_dir, \"working_data/\")\n",
    "meteo_dir = root_dir + \"datasets/meteo_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'old_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d57e26d470dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_meteo_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_extract_features_meteo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeteo_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_meteo_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9eeea1519198>\u001b[0m in \u001b[0;36mload_extract_features_meteo\u001b[0;34m(meteo_dir)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmeteo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_preprocess_meteo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeteo_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmeteo_daily\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_daily_meteo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeteo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0maggregated_meteo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_meteo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeteo_daily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmeteo_all_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maggregated_meteo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeteo_daily\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9eeea1519198>\u001b[0m in \u001b[0;36magg_meteo\u001b[0;34m(meteo)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0magg_meteo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeteo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_feature_extraction_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeteo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0maggregated_meteo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_with_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeteo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maggregated_meteo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-1972bcbfbd73>\u001b[0m in \u001b[0;36maggregate_with_config\u001b[0;34m(df, config)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_agg_settings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcol_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_col_with_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_agg_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mall_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-1972bcbfbd73>\u001b[0m in \u001b[0;36magg_col_with_settings\u001b[0;34m(col, list_aggregations)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0magg_settings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_aggregations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnew_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_agg_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0maggregated_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0magg_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregated_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-1972bcbfbd73>\u001b[0m in \u001b[0;36magg_col\u001b[0;34m(col, agg_settings)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mshifted_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregated_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mshifted_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mshifted_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'old_index' is not defined"
     ]
    }
   ],
   "source": [
    "all_meteo_features = load_extract_features_meteo(meteo_dir)\n",
    "all_meteo_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meteo_features[\"cloudCoverTotal_nanmean_1_7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_forecast_to_dataset = {\"Total_cloud_cover_entire_atmosphere_Mixed_intervals_Average\": \"cloudCoverTotal\",\n",
    "                            'u-component_of_wind_height_above_ground': \"windAngleX\", \n",
    "                            'v-component_of_wind_height_above_ground': \"windAngleY\",\n",
    "                            'Wind_speed_gust_surface': \"windSpeed\", \n",
    "                            'Total_precipitation_surface_Mixed_intervals_Accumulation': \"totalAccumulatedPrecipitation\", \n",
    "                            \"Temperature_height_above_ground\": 'airTemperature', \n",
    "                            'Maximum_temperature_height_above_ground_Mixed_intervals_Maximum': 'maximumTemperatureOverPeriodSpecified', \n",
    "                            'Minimum_temperature_height_above_ground_Mixed_intervals_Minimum': 'minimumTemperatureAtHeightAndOverPeriodSpecified',\n",
    "                            'Temperature_surface': 'soilTemperature', \n",
    "                            'Relative_humidity_height_above_ground': 'relativeHumidity', \n",
    "                            'Pressure_height_above_ground': 'pressure', \n",
    "                            'Pressure_reduced_to_MSL_msl': 'pressureReducedToMeanSeaLevel',\n",
    "                            \"Dewpoint_temperature_height_above_ground\": \"dewpointTemperature\"\n",
    "                           }\n",
    "\n",
    "required_data = list(name_forecast_to_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: распараллелить получение предсказаний, попробовать пробивать по региону\n",
    "\n",
    "def get_weather_forecast(points: list, required_data):\n",
    "    url = \"http://thredds.ucar.edu/thredds/catalog/grib/NCEP/GFS/Global_0p5deg/catalog.xml\"\n",
    "    point_outputs = []\n",
    "    \n",
    "    client = get_latest_dataset_client(url)\n",
    "    query = build_base_query(client, required_data)\n",
    "    \n",
    "    for point in points:\n",
    "        query = update_query_point(query, point)\n",
    "        print(\"get data\")#, query)\n",
    "        t1 = time()\n",
    "        out = client.get_data(query)\n",
    "        print(\"Got data, time:\", time() - t1)\n",
    "        point_outputs.append(out)\n",
    "    \n",
    "    return point_outputs\n",
    "\n",
    "\n",
    "def get_latest_dataset_client(catalog_url):\n",
    "    gfs_cat = TDSCatalog(catalog_url)\n",
    "    ncss_client = gfs_cat.latest.subset()\n",
    "    return ncss_client\n",
    "\n",
    "\n",
    "def build_base_query(client, required_data):\n",
    "    query = client.query()\n",
    "    \n",
    "    query = query.variables(*required_data)\n",
    "    query = query.all_times()\n",
    "    query = query.accept(\"netCDF4\")\n",
    "\n",
    "    return query\n",
    "\n",
    "\n",
    "def update_query_point(query, point): #also deletes old point\n",
    "    query = query.lonlat_point(*point)\n",
    "    return query\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_forecast(forecasted_dataset):\n",
    "    data = xarray.backends.NetCDF4DataStore(forecasted_dataset)\n",
    "    \n",
    "    values = {}\n",
    "    for var_name in required_data:\n",
    "        var_value = get_var_values(data, var_name)\n",
    "        values[var_name] = var_value\n",
    "        \n",
    "    values = pd.DataFrame.from_dict(values, orient=\"columns\")\n",
    "    timestamps = get_timestamps(data)\n",
    "    values.index = timestamps\n",
    "    \n",
    "    values = fill_forecast_nan(values)\n",
    "    return values\n",
    "    \n",
    "    \n",
    "def get_timestamps(data):\n",
    "    attrs = data.get_attrs()\n",
    "    start_time = pd.to_datetime(attrs[\"time_coverage_start\"])\n",
    "    \n",
    "    hours_from_start = data.get_variables()[\"time\"]\n",
    "#     print(hours_from_start)\n",
    "    time_deltas = timedelta_from_hours(hours_from_start)[:-1]\n",
    "    \n",
    "    timestamps = start_time + time_deltas\n",
    "    \n",
    "    timestamps.name = \"datetime\"\n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def timedelta_from_hours(hours):\n",
    "    return pd.to_timedelta(hours.values.flatten(), \"h\") \n",
    "\n",
    "\n",
    "def get_var_values(data, name):\n",
    "    values = data.get_variables()[name].values\n",
    "    shape = values.shape\n",
    "    if len(shape) == 3:\n",
    "        values = values[:, :, 0]\n",
    "        \n",
    "    if len(shape) > 3:\n",
    "        raise ValueError(\"В Forecast размерность values > 3\")\n",
    "        \n",
    "    return values.flatten()[:-1]\n",
    "\n",
    "\n",
    "def fill_forecast_nan(df):\n",
    "    df = fill_with_first_notnan(df, df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_with_first_notnan(df, cols):\n",
    "    cols = list(cols)\n",
    "    \n",
    "    for col in cols:\n",
    "        notnan = df.loc[df[col].notnull(), col]\n",
    "        first_notnan = notnan.iloc[0]\n",
    "        df.loc[df[col].isna(), col] = first_notnan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_from_forecast(point_forecast):\n",
    "    point_forecast = rescale_forecast(point_forecast)\n",
    "    point_forecast = rename_forecast(point_forecast)\n",
    "    point_forecast = agg_forecast_features(point_forecast)\n",
    "    \n",
    "    return point_forecast\n",
    "    \n",
    "    \n",
    "def rescale_forecast(forecast):\n",
    "    forecast = rescale_cloud_cover(forecast)\n",
    "    forecast = rescale_wind_vector(forecast)\n",
    "    forecast = rescale_temperature(forecast)\n",
    "    forecast = rescale_pressure(forecast)\n",
    "    return forecast\n",
    "\n",
    "\n",
    "def rename_forecast(df):\n",
    "    new_names = name_forecast_to_dataset # add them to utils??\n",
    "    df.rename(columns=new_names, inplace=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "def agg_forecast_features(forecast):\n",
    "    # сделать аггрегирование, как у обычного dataset'а\n",
    "    return forecast \n",
    "    \n",
    "def rescale_cloud_cover(df):\n",
    "    df[\"Total_cloud_cover_entire_atmosphere_Mixed_intervals_Average\"] /= 10 # rescaling from 0-100 to 0-10\n",
    "    return df\n",
    "\n",
    "\n",
    "def rescale_wind_vector(df):\n",
    "    wind_x = df['u-component_of_wind_height_above_ground']\n",
    "    wind_y = df['v-component_of_wind_height_above_ground']\n",
    "    vector_module = (wind_x ** 2 + wind_y ** 2)**0.5\n",
    "    \n",
    "    wind_x = np.sign(wind_x) * wind_x / vector_module\n",
    "    wind_y = np.sign(wind_y) * wind_y / vector_module\n",
    "    \n",
    "    # if vector_module == 0, wind_x and wind_y are np.nan\n",
    "    wind_x[vector_module == 0] = 0\n",
    "    wind_y[vector_module == 0] = 0\n",
    "    \n",
    "    \n",
    "    df['u-component_of_wind_height_above_ground'] = wind_x\n",
    "    df['v-component_of_wind_height_above_ground'] = wind_y\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def rescale_temperature(df):\n",
    "    temperature_cols = [\"Temperature_height_above_ground\", \"Temperature_surface\",\n",
    "                        \"Maximum_temperature_height_above_ground_Mixed_intervals_Maximum\",\n",
    "                        \"Minimum_temperature_height_above_ground_Mixed_intervals_Minimum\",\n",
    "                        \"Dewpoint_temperature_height_above_ground\"\n",
    "                       ]\n",
    "    \n",
    "    df[temperature_cols] -= 273 # temperature there is in absolute form\n",
    "    return df\n",
    "\n",
    "\n",
    "def rescale_pressure(df):\n",
    "    pressure_cols = [\"Pressure_height_above_ground\", \"Pressure_reduced_to_MSL_msl\"]\n",
    "    df[pressure_cols] /= 100\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add ability to specify days from forecast\n",
    "\n",
    "def get_forecast_dataset(forecast_coords):\n",
    "    forecast = get_weather_forecast(forecast_coords, required_data)\n",
    "    point_datasets = []\n",
    "    \n",
    "    for point in forecast:\n",
    "        forecast_data = parse_forecast(point)\n",
    "        point_dataset = make_dataset_from_forecast(forecast_data)\n",
    "        point_datasets.append(point_dataset)\n",
    "\n",
    "    \n",
    "forecast_coords = [(135, 50), (66, 45), (-105, 40)] # переделать в dataframe с парами id: coords\n",
    "forecast_df = get_forecast_dataset(forecast_coords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
