{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../working_data/\"\n",
    "SRC_DATA_DIR = \"../datasets/processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBuilder:\n",
    "    # TODO: функции доступа к date и id, тк сейчас они то в колоноках,\n",
    "    # то в индексах, так что вылетают рандомные ошибки\n",
    "    def __init__(self, hydro, meteo, s2m_dict):\n",
    "        self.hydro = self.prepare_df(hydro)\n",
    "        self.meteo = self.prepare_df(meteo)\n",
    "        self.s2m_dict = s2m_dict\n",
    "        \n",
    "    def prepare_df(self, df):\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        first2cols = list(df.columns[:2])\n",
    "        df.set_index(first2cols, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def build(self):\n",
    "        self.fill_missing_dates()\n",
    "        self.merged = self.merge_parts()\n",
    "        self.extract_merged_x_y()\n",
    "        \n",
    "        return self.features, self.target\n",
    "    \n",
    "    def fill_missing_dates(self):\n",
    "        min_date, max_date = self.min_max_data_date()\n",
    "        \n",
    "        new_hydro_idx = self.create_all_dates_index(self.hydro, min_date, max_date)\n",
    "        new_meteo_idx = self.create_all_dates_index(self.meteo, min_date, max_date)\n",
    "        \n",
    "        fill_val = np.nan\n",
    "        self.hydro = self.hydro.reindex(new_hydro_idx, fill_value=fill_val)\n",
    "        self.meteo = self.meteo.reindex(new_meteo_idx, fill_value=fill_val)\n",
    "    \n",
    "    def min_max_data_date(self):\n",
    "        dates_hydro = self.hydro.index.get_level_values(\"date\")\n",
    "        dates_meteo = self.meteo.index.get_level_values(\"date\")\n",
    "        \n",
    "        min_date = min(dates_hydro.min(), dates_meteo.min())\n",
    "        max_date = max(dates_hydro.max(), dates_meteo.max())\n",
    "        \n",
    "        return min_date, max_date\n",
    "    \n",
    "    def create_all_dates_index(self, df, min_date, max_date):\n",
    "        id_idxs = df.index.get_level_values(0).unique()\n",
    "        new_date_index = pd.date_range(min_date, max_date, name=\"date\")\n",
    "        \n",
    "        all_dates_index = pd.MultiIndex.from_product([id_idxs, new_date_index])\n",
    "        \n",
    "        return all_dates_index\n",
    "    \n",
    "    def merge_parts(self):\n",
    "        nearest_meteo_id = self.hydro_to_meteo_map_col()\n",
    "        \n",
    "        hydro = self.hydro.reset_index()\n",
    "        meteo = self.meteo\n",
    "\n",
    "        merged = hydro.merge(meteo, left_on=[nearest_meteo_id, \"date\"], right_on=[\"stationNumber\", \"date\"], how=\"left\")\n",
    "        merged.set_index([\"id\", \"date\"], inplace=True)\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def hydro_to_meteo_map_col(self):\n",
    "        hydro_id = self.hydro.index.get_level_values(\"id\")\n",
    "        hydro_nearest_meteo = hydro_id.map(self.s2m_dict)\n",
    "        \n",
    "        return hydro_nearest_meteo\n",
    "    \n",
    "    def extract_merged_x_y(self):\n",
    "        feature_cols = list(self.merged.columns)\n",
    "        feature_cols.remove(\"target\")\n",
    "\n",
    "        self.features = self.merged[feature_cols]\n",
    "        self.target = self.merged[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro = pd.read_csv(DATA_DIR + \"hydro_features.csv\")\n",
    "meteo = pd.read_csv(DATA_DIR + \"meteo_features.csv\")\n",
    "\n",
    "hydro = utils.reduce_memory_usage(hydro)\n",
    "meteo = utils.reduce_memory_usage(meteo)\n",
    "\n",
    "s2m = pd.read_csv(DATA_DIR + \"handmade_s2m.csv\", index_col=0)\n",
    "s2m_dict = s2m.to_dict()[\"meteo_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = DataBuilder(hydro, meteo, s2m_dict)\n",
    "features, target = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hydro, meteo, builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop objects where target is none\n",
    "target_notnan_mask = target.notna()\n",
    "features, target = features[target_notnan_mask], target[target_notnan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DatasetRetriever(Dataset):\n",
    "#     def __init__(self, features, target):\n",
    "#         super().__init__()\n",
    "#         self.features = features\n",
    "#         self.target = target\n",
    "        \n",
    "#     def __getitem__(self, index: int):\n",
    "#         obj_features = self.features.iloc[index]\n",
    "#         obj_target = self.target.iloc[index]\n",
    "        \n",
    "#         return obj_features, obj_target\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.features)\n",
    "    \n",
    "# data_retr = DatasetRetriever(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training model for single post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesValFoldRetriever:\n",
    "    def __init__(self, features, labels, nfolds=12, val_width=30):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.dates = self.features.index.get_level_values(\"date\")\n",
    "        self.uniq_dates = sorted(self.dates.unique())\n",
    "        self.unique_dates_num = len(self.uniq_dates)\n",
    "        \n",
    "        self.nfolds = nfolds\n",
    "        self.val_width = val_width\n",
    "        \n",
    "        self.set_folds_periods()\n",
    "        \n",
    "        \n",
    "    def set_folds_periods(self):\n",
    "        self.train_masks = []\n",
    "        self.val_masks = []\n",
    "        \n",
    "        train_start = 0\n",
    "        last_idx = self.unique_dates_num - 1\n",
    "        \n",
    "        for fold_idx in range(self.nfolds):\n",
    "            folds_till_end = self.nfolds - fold_idx + 1\n",
    "            train_end = last_idx - folds_till_end * self.val_width\n",
    "            \n",
    "            val_start = train_end\n",
    "            val_end = val_start + self.val_width\n",
    "            \n",
    "            train_dates = self.uniq_dates[train_start: train_end]\n",
    "            val_dates = self.uniq_dates[val_start: val_end]\n",
    "            \n",
    "            train_date_mask = self.dates.isin(train_dates)\n",
    "            val_date_mask = self.dates.isin(val_dates)\n",
    "            \n",
    "            self.train_masks.append(train_date_mask)\n",
    "            self.val_masks.append(val_date_mask)\n",
    "        \n",
    "#     def __next__(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        for fold_idx in range(self.nfolds):\n",
    "            train_period = self.train_masks[fold_idx]\n",
    "            val_period = self.val_masks[fold_idx]\n",
    "            \n",
    "            train_features, train_labels = self.features[train_period], self.labels[train_period]\n",
    "            val_features, val_labels = self.features[val_period], self.labels[val_period]\n",
    "            \n",
    "            yield train_features, train_labels, val_features, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LgbModel:\n",
    "    \"\"\"Controlles process of training model on data from single station\"\"\"\n",
    "    def __init__(self, model_config):\n",
    "        self.lgb_param = model_config\n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        dataset = lgb.Dataset(x, y)\n",
    "        self.model = lgb.train(self.lgb_param, dataset)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        return self.model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StationModelsManager:\n",
    "    \"\"\"creates StattionFitters for every station_id from __init__, \n",
    "    Cat train and evaluate these models, return final metric for all stations\"\"\"\n",
    "    def __init__(self, station_ids, model_class, model_config):\n",
    "        self.station_ids = station_ids\n",
    "        self.models = {}\n",
    "        \n",
    "        for id_stat in self.station_ids:\n",
    "            model = model_class(model_config)\n",
    "            self.models[id_stat] = model\n",
    "        \n",
    "    \n",
    "    def fit(self, features: pd.DataFrame, target: pd.DataFrame):\n",
    "        \n",
    "        for station_id, model in self.models.items():\n",
    "            station_features = self._get_station_data(features, station_id)\n",
    "            station_target = self._get_station_data(target, station_id)\n",
    "            model.fit(station_features, station_target)\n",
    "            \n",
    "    def predict(self, features: pd.DataFrame):\n",
    "        answers = np.zeros(len(features))\n",
    "        \n",
    "        for station_id, model in self.models.items():\n",
    "            station_features = self._get_station_data(features, station_id)\n",
    "            station_model = self.models[station_id]\n",
    "            preds = station_model.predict(station_features)\n",
    "            \n",
    "            curr_station_mask = self._curr_station_mask(features, station_id)\n",
    "            answers[curr_station_mask] = preds\n",
    "            \n",
    "        return answers\n",
    "            \n",
    "    def _get_station_data(self, df, station_id):\n",
    "        station_mask = self._curr_station_mask(df, station_id)\n",
    "        df_station = df.iloc[station_mask]\n",
    "        return df_station\n",
    "    \n",
    "    def _curr_station_mask(self, df, station_id):\n",
    "        id_col = df.reset_index()[\"id\"]\n",
    "#         print(\"ID\", id_col)\n",
    "#         print(\"ST\", station_id)\n",
    "        station_mask = (id_col == station_id).values\n",
    "        \n",
    "        return station_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidator:\n",
    "    def __init__(self, folds, model, metric):\n",
    "        \"\"\"\n",
    "        :param folds: iterable containing t_x, t_y, v_x, v_y\"\"\"\n",
    "        self.folds = folds\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        \n",
    "    def run_cv(self):\n",
    "        self.metric_vals = []\n",
    "        \n",
    "        for fold_num, (xtrain, ytrain, xval, yval) in enumerate(self.folds):\n",
    "            print(f\"starting {fold_num} fold\")\n",
    "            model.fit(xtrain, ytrain)\n",
    "            val_preds = model.predict(xval)\n",
    "            \n",
    "            metric_val = self.metric(val_preds, yval)\n",
    "            self.metric_vals.append(metric_val)\n",
    "            \n",
    "        return np.mean(self.metric_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_station_ids = [6005, 6022, 6027, 5004, 5012, 5024, 5805]\n",
    "target_stations_mask = features.reset_index()[\"id\"].isin(target_station_ids).values\n",
    "\n",
    "features = features[target_stations_mask]\n",
    "target = target[target_stations_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_param = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "folds_retriever = TimeSeriesValFoldRetriever(features, target, nfolds=12, val_width=31)\n",
    "model = StationModelsManager(target_station_ids, LgbModel, lgb_param)\n",
    "\n",
    "cross_val = CrossValidator(folds_retriever, model, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 0 fold\n",
      "starting 1 fold\n",
      "starting 2 fold\n",
      "starting 3 fold\n",
      "starting 4 fold\n",
      "starting 5 fold\n",
      "starting 6 fold\n",
      "starting 7 fold\n",
      "starting 8 fold\n",
      "starting 9 fold\n",
      "starting 10 fold\n",
      "starting 11 fold\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.591880691924104"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val.run_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.292471468899838,\n",
       " 10.328676253011963,\n",
       " 3.7600630325865003,\n",
       " 1.3703476976882962,\n",
       " 18.52845378919857,\n",
       " 31.826512861673177,\n",
       " 16.015466698602047,\n",
       " 2.776535607163889,\n",
       " 2.148834364743927,\n",
       " 2.8392387102496612,\n",
       " 3.2006560396839623,\n",
       " 4.015311779587401]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val.metric_vals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
